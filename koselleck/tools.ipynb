{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.koselleck import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_source(code):\n",
    "    import IPython\n",
    "    def _jupyterlab_repr_html_(self):\n",
    "        from pygments import highlight\n",
    "        from pygments.formatters import HtmlFormatter\n",
    "\n",
    "        fmt = HtmlFormatter()\n",
    "        style = \"<style>{}\\n{}\\n{}\\n</style>\".format(\n",
    "            fmt.get_style_defs(\".output_html\"),\n",
    "            fmt.get_style_defs(\".jp-RenderedHTML\"),\n",
    "            '.jp-RenderedHTML span { font-size:0.8em }'\n",
    "        )\n",
    "        return style + highlight(self.data, self._get_lexer(), fmt)\n",
    "\n",
    "    # Replace _repr_html_ with our own version that adds the 'jp-RenderedHTML' class\n",
    "    # in addition to 'output_html'.\n",
    "    IPython.display.Code._repr_html_ = _jupyterlab_repr_html_\n",
    "    return IPython.display.Code(data=code, language=\"python3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_source(\"print('Hello world')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source a function\n",
    "def src(x):\n",
    "    from IPython.display import Code,display\n",
    "    if type(x)!=str:\n",
    "        import inspect\n",
    "        x=inspect.getsource(x)\n",
    "    display(display_source(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numlines(fname):\n",
    "    with open(fname) as f:\n",
    "        for i, l in enumerate(f):\n",
    "            pass\n",
    "    return i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_numlines('tools.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upfig(fnfn,uproot=UPROOT):\n",
    "    ofnfn=os.path.join(uproot,os.path.basename(fnfn))\n",
    "    os.system(f'dbu upload {fnfn} {ofnfn}')\n",
    "    return os.system(f'dbu share {ofnfn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as iImage\n",
    "def print_img(fn):\n",
    "    #return iImage(filename=fn)\n",
    "    with open(fn,'rb') as f:\n",
    "        display(widgets.Image(value=f.read(),format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def df_to_png(df,ofn='fig.dataframe.png',style=None):\n",
    "#     import imgkit\n",
    "    \n",
    "#     STYLE=\"\"\"\n",
    "#         table { border:1px dotted silver; }\n",
    "#         td,th { font-family: \"Baskerville\", \"Libre Baskerville\", \"Georgia\", serif; }\n",
    "#         tbody tr:nth-child(even)   { background-color:#eee; }\n",
    "#         tbody tr:nth-child(odd)    { background-color:#fff; }\n",
    "#         thead { background-color:#ddd; }\n",
    "#     \"\"\"\n",
    "#     style = STYLE if not style else style\n",
    "#     style=f'<style type=\"text/css\">{style}</style>'    \n",
    "#     ohtml=df.to_html()\n",
    "#     o='<html><body>'+style + ohtml+'</body></html>'\n",
    "#     imgkit.from_string(o, ofn, options={'--quiet':''})\n",
    "#     print_img(ofn)\n",
    "#     return ofn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_year(y):\n",
    "    if type(y)==int: return y\n",
    "    if type(y)==float: return int(y)\n",
    "    if type(y)==str:\n",
    "        x=''.join([x for x in y if x.isdigit()][:4])\n",
    "        if x and x.isdigit(): return int(x)\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodize(y,ybin=5):\n",
    "    y1=y//ybin*ybin\n",
    "    y2=y1+ybin\n",
    "    return f'{y1}-{y2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodize_bystep(y,ybin,ymin,ymax=10000):\n",
    "    if y<ymin or y>ymax: return ''\n",
    "    ystep=ymin\n",
    "    for ystep2 in range(ymin,ymax+ybin,ybin):\n",
    "        if y>=ystep and y<ystep2:\n",
    "            return f'{ystep}-{ystep2}'\n",
    "        ystep=ystep2\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periods_bystep(ymin=YMIN, ymax=YMAX, ybin=YEARBIN):\n",
    "    steps=list(range(ymin,ymax+ybin,ybin))\n",
    "    step1=steps[0]\n",
    "    l=[]\n",
    "    for step2 in steps[1:]:\n",
    "        o=f'{step1}-{step2}'\n",
    "        l+=[o]\n",
    "        step1=step2\n",
    "    return l\n",
    "\n",
    "# get_periods_bystep(ymin=1700, ymax=1900, ybin=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodize(1848)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random\n",
    "def periodize_sattelzeit(y,use_dates=True):\n",
    "    if 1700<=y<1770: return '1700-1770' if use_dates else 'Before'\n",
    "    if 1770<=y<1830: return '1770-1830' if use_dates else 'During'\n",
    "    if 1830<=y<1900: return '1830-1900' if use_dates else 'After'\n",
    "\n",
    "def periodize_sattelzeit_binary(y):\n",
    "    if 1700<=y<1770: return '1700-1770'\n",
    "    if 1830<=y<1900: return '1830-1900'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodize_sattelzeit(1789,use_dates=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(ifn,key='',**attrs):\n",
    "    if not os.path.exists(ifn): return\n",
    "    import pandas as pd\n",
    "    ext = os.path.splitext(ifn.replace('.gz',''))[-1][1:]\n",
    "    if ext=='csv':\n",
    "        return pd.read_csv(ifn,**attrs)\n",
    "    elif ext in {'xls','xlsx'}:\n",
    "        return pd.read_excel(ifn,**attrs)\n",
    "    elif ext in {'txt','tsv'}:\n",
    "        return pd.read_csv(ifn,sep='\\t',**attrs)\n",
    "    elif ext=='ft':\n",
    "        return pd.read_feather(ifn,**attrs)\n",
    "    elif ext=='pkl':\n",
    "        return pd.read_pickle(ifn,**attrs)\n",
    "    elif ext=='h5':\n",
    "        return pd.read_hdf(ifn, key=key,**attrs)\n",
    "    else:\n",
    "        raise Exception(f'[save_df()] What kind of df is this: {ifn}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tokenize_fast(line,lower=True,incl_punct=False):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "    line=line.lower() if lower else line\n",
    "    tokens = re.findall(\n",
    "        r\".*?[A-Z]{2,}(?![a-z])|[A-Z][a-z]+(?=[A-Z])|[\\'\\w\\-]+\",\n",
    "        # r'\\w+',\n",
    "        line\n",
    "    )\n",
    "    if not incl_punct: tokens = [w.strip(punctuation) for w in tokens]\n",
    "    tokens = [w for w in tokens if w]\n",
    "    return tokens\n",
    "\n",
    "# set tokenizer\n",
    "tknz=tokenize_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tknz('ThiS,is,a sentence. !! ---hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_words(word_or_words):\n",
    "    return tokenize_fast(word_or_words) if type(word_or_words)==str else word_or_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_corpora_periods(\n",
    "        word_or_words, period_or_periods=None, corpus_or_corpora=DEFAULT_CORPUS,\n",
    "        ybin=YBIN_WDIST, ymin=YMIN_WDIST, ymax=YMAX_WDIST):\n",
    "    words=to_words(word_or_words)\n",
    "    corpora=to_words(corpus_or_corpora)\n",
    "    periods=to_words(period_or_periods) if period_or_periods else get_periods_bystep(\n",
    "        ymin=ymin,ymax=ymax,ybin=ybin\n",
    "    )\n",
    "    return words,corpora,periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_fig(data=None, theme='minimal',text_size=8, figure_size=(8,8), **aesd):\n",
    "    p9.options.figure_size=figure_size\n",
    "    p9.options.dpi=600\n",
    "    fig=p9.ggplot(p9.aes(**aesd), data=data)\n",
    "    fig+=getattr(p9,f'theme_{theme}')()\n",
    "    fig+=p9.theme(\n",
    "        text=p9.element_text(size=text_size),\n",
    "#         plot_background=p9.element_rect(fill='white')\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_df('../data/data.model.paths.default.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display,Markdown\n",
    "import pandas as pd\n",
    "\n",
    "def printm(x):\n",
    "    if type(x)==pd.DataFrame: x=x.to_markdown()\n",
    "    display(Markdown(x))\n",
    "\n",
    "def markdwn(x):\n",
    "    html = markdown.markdown(x,extensions=['tables'])\n",
    "    return HTML(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Googlesheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sheet(sh_id=GSPREAD_NAME):\n",
    "    return Spread(sh_id) if type(sh_id)==str else sh_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sh=get_sheet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sheet(df,sh_or_id=GSPREAD_NAME,index=True,replace=True):\n",
    "    sh = get_sheet(sh_or_id)\n",
    "    sh.df_to_sheet(df,index=index,replace=replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GSPREAD_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9cca0141fb99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mread_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_or_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGSPREAD_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0msh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msh_or_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdfanno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#dfanno['rank']=dfanno['rank'].replace({'':-1}).apply(int)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#dfanno=dfanno.sort_values('rank')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GSPREAD_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "def read_sheet(sh_or_id=GSPREAD_NAME):\n",
    "    sh = get_sheet(sh_or_id)\n",
    "    dfanno=sh.sheet_to_df()\n",
    "    #dfanno['rank']=dfanno['rank'].replace({'':-1}).apply(int)\n",
    "    #dfanno=dfanno.sort_values('rank')\n",
    "    return dfanno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_png(df,ofn='fig.dataframe.png',style=None,force_html=True,replaced={}):\n",
    "    import imgkit\n",
    "    \n",
    "    STYLE=\"\"\"\n",
    "        table { border:1px dotted silver; }\n",
    "        td,th { font-family: \"Times New Roman\", \"Baskerville\", \"Libre Baskerville\", \"Georgia\", serif; }\n",
    "        tbody tr:nth-child(even)   { background-color:#eee; }\n",
    "        tbody tr:nth-child(odd)    { background-color:#fff; }\n",
    "        tbody { vertical-align: top; }\n",
    "        thead { background-color:#ddd; }\n",
    "    \"\"\"\n",
    "    style = STYLE if not style else style\n",
    "    style=f'<style type=\"text/css\">{style}</style>'    \n",
    "    ohtml=df.to_html()\n",
    "    if force_html: ohtml=ohtml.replace('&gt;','>').replace('&lt;','<')\n",
    "    for k,v in replaced.items(): ohtml=ohtml.replace(k,v)\n",
    "    o='<html><body>'+style + ohtml+'</body></html>'\n",
    "    imgkit.from_string(o, ofn, options={'--quiet':''})\n",
    "    print_img(ofn)\n",
    "    return ofn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def classify_vector_change(row,perc_threshold=75,z_threshold=1,z_threshold2=.5):\n",
    "#     name=row.vector\n",
    "#     ns=str(name).split('.')[0].split('-')\n",
    "#     n1,n2=ns[0],ns[-1]\n",
    "#     # res='~'#f'{n1}~{n2}'\n",
    "#     res='+' if row.mean_diff>0 else '-'\n",
    "#     if row.mean_diff_p<0.05 and row.perc>perc_threshold:\n",
    "#         if row.mean_diff>0:\n",
    "#             ## increases\n",
    "#             # decreases\n",
    "#             if row.mean2<-z_threshold and row.mean1<-z_threshold:\n",
    "#                 # still over the line for conc\n",
    "#                 res=f'{n2}-'\n",
    "#             elif row.mean2>z_threshold:\n",
    "#                 # we're over the line for pos\n",
    "#                 if row.mean1>z_threshold:\n",
    "#                     # already was though\n",
    "#                     res=f'{n1}+'                    \n",
    "#                 elif row.mean1<-z_threshold:\n",
    "#                     # jumped all the way from neg to pos!\n",
    "#                     res=f'{n1}+++' \n",
    "#                 elif row.mean1<z_threshold2:\n",
    "#                     # jumped part of the way to become new\n",
    "#                     res=f'{n1}++'\n",
    "#                 else:\n",
    "#                     res=f'{n1}+'\n",
    "#             elif row.mean1<-z_threshold:\n",
    "#                 # really this is a loss of the prior\n",
    "#                 res=f'{n2}--'\n",
    "#             else:\n",
    "#                 res=f'{n1}+'\n",
    "#         else:\n",
    "#             # decreases\n",
    "#             if row.mean2>z_threshold and row.mean1>z_threshold:\n",
    "#                 # still over the line for abs\n",
    "#                 res=f'{n1}-'\n",
    "#             elif row.mean2<-z_threshold:\n",
    "#                 # over the line for neg\n",
    "#                 if row.mean1<-z_threshold:\n",
    "#                     # already was tho\n",
    "#                     res=f'{n2}+'\n",
    "#                 elif row.mean1>z_threshold:\n",
    "#                     # jumped all the way from pos to neg\n",
    "#                     res=f'{n2}+++'\n",
    "#                 elif row.mean1>-z_threshold2:\n",
    "#                     # jumped part of the way to become new\n",
    "#                     res=f'{n2}++'\n",
    "#                 else:\n",
    "#                     res=f'{n2}+'\n",
    "#             elif row.mean1>z_threshold:\n",
    "#                 # really this is a loss of the prior\n",
    "#                 res=f'{n1}--'\n",
    "#             else:\n",
    "#                 res=f'{n2}+'\n",
    "#     return res\n",
    "\n",
    "# DFCC=None\n",
    "# DFCC_CACHE_FN=os.path.join(PATH_DATA,'data.classed_changes.pkl')\n",
    "# def get_classed_changes(cache=True):\n",
    "#     global DFCC\n",
    "#     if DFCC is None:\n",
    "#         if cache and os.path.exists(DFCC_CACHE_FN):\n",
    "#             df=pd.read_pickle(DFCC_CACHE_FN)\n",
    "#         else:\n",
    "#             df=get_dfchange_from_decade_data(wide=False).reset_index()\n",
    "#             df['perc']=df.mean_diff_t_abs.apply(lambda x: percentileofscore(df.mean_diff_t_abs, x))\n",
    "#             dfchsz=get_dfchange_from_sattelzeit_models().reset_index()\n",
    "#             df['change']=df.progress_apply(classify_vector_change,axis=1)\n",
    "#             dfchsz['change']=dfchsz['class_change']\n",
    "#             df=df.append(dfchsz)\n",
    "#             startcols=['word','vector','change']\n",
    "#             df=df[startcols + [c for c in df.columns if c not in set(startcols)]]\n",
    "#             df['mean_diff_abs']=df['mean_diff'].apply(abs)\n",
    "#             df['change_rank']=[\n",
    "#                 x.count('+') + x.count('-') if len(x)>1 else 0\n",
    "#                 for x in df.change\n",
    "#             ]\n",
    "#             if cache: df.to_pickle(DFCC_CACHE_FN)\n",
    "#         DFCC=df\n",
    "#     return DFCC.sort_values(['change_rank','mean_diff_abs'],ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "# def get_dfpiv(key, df=None, fn=FN_VECTOR_SCORES_RUNS, ymin=1700, ymax=1900, words=None, z=False, axis=1):\n",
    "#     if df is None: df=pd.read_pickle(fn)\n",
    "#     pwdf=df.groupby(['period','word']).mean().reset_index()\n",
    "#     pwdf['period']=[int(p[:4]) for p in pwdf.period]\n",
    "#     pwdf=pwdf.query(f'{ymin}<=period<{ymax}')\n",
    "#     pwdfpiv=pwdf.pivot('word','period',key)\n",
    "#     if words: pwdfpiv=pwdfpiv.reset_index()[pwdfpiv.reset_index().word.isin(set(words))].set_index('word')\n",
    "#     if z: pwdfpiv=to_z(pwdfpiv,axis=axis)\n",
    "#     return pwdfpiv\n",
    "    \n",
    "\n",
    "# def get_dfpiv_abs(key=FIELD_ABS_KEY,**y):\n",
    "#     return get_dfpiv(key,**y)\n",
    "    \n",
    "# def get_pathdf_models_bydecade(ymin=1700,ymax=1900):\n",
    "#     return get_pathdf_models().query(f'period_len==10 & {ymin}<=period_start<{ymax}')\n",
    "# def get_pathdf_models_byyear(ymin=1700,ymax=1900):\n",
    "#     return get_pathdf_models().query(f'period_len==2 & {ymin}<=period_start<{ymax}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DFPKG=None\n",
    "# def get_df_package():\n",
    "#     global DFPKG\n",
    "#     if DFPKG is not None: return DFPKG\n",
    "#         # load decade level data\n",
    "#     dfpiv_abs,dfpiv_freq = get_decade_level_data()\n",
    "#     # load diff data by run\n",
    "#     dfruns=pd.read_csv(FN_CHANGE_RUNS).set_index('word')\n",
    "#     dfruns_dec=pd.read_pickle(FN_VECTOR_SCORES_RUNS)\n",
    "#     # Load diffdata avg\n",
    "#     dfchange=get_dfchange()\n",
    "#     DFPKG=(dfchange,dfruns,dfpiv_abs,dfpiv_freq,dfruns_dec,get_dfpiv_ambig())\n",
    "#     return DFPKG\n",
    "\n",
    "# def get_dfpiv_ambig(fn=FN_AMBIGUITY,z=True):\n",
    "#     ambdf=pd.read_csv(FN_AMBIGUITY)\n",
    "#     odf=ambdf.groupby('period').mean()\n",
    "#     odf.index=[int(p[:4]) for p in odf.index]\n",
    "#     odf=odf.T\n",
    "#     if z: odf=to_z(odf)\n",
    "#     return odf\n",
    "\n",
    "# def get_dfpiv_freq(words=None,ymin=1700,ymax=1900,z=False):\n",
    "#     df=pd.read_csv(FN_FREQ_DEC_MODELS).set_index('word')\n",
    "#     df.columns=[int(x[:4]) for x in df.columns]\n",
    "#     df=df[[y for y in df.columns if y>=ymin and y<ymax]]\n",
    "#     if words: df=df.reset_index()[df.reset_index().word.isin(set(words))].set_index('word')\n",
    "#     if z: df=to_z(df, axis=0)\n",
    "#     return df\n",
    "\n",
    "# def get_decade_level_data(words=None,z=True):\n",
    "#     if os.path.exists(FN_DATA_CACHE_DEC):\n",
    "#         with open(FN_DATA_CACHE_DEC,'rb') as f:\n",
    "#             return pickle.load(f)\n",
    "    \n",
    "#     # load decade level data\n",
    "#     if words is None: words=get_valid_words()\n",
    "#     dfpiv_abs=get_dfpiv_abs(words=words,z=z)#.dropna()\n",
    "#     dfpiv_freq=get_dfpiv_freq(words=words,z=z)#.dropna()\n",
    "#     o=dfpiv_abs,dfpiv_freq\n",
    "#     with open(FN_DATA_CACHE_DEC,'wb') as of:\n",
    "#         pickle.dump(o,of)\n",
    "#     return o\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# VECNAMES=None\n",
    "# def get_vector_names():\n",
    "#     global VECNAMES\n",
    "#     if not VECNAMES: VECNAMES=list(pd.read_csv(FN_VECTOR_SCORES_DIFFMEANS).vector.unique())\n",
    "#     return VECNAMES\n",
    "\n",
    "# def classify_abstractness(row,perc_threshold=70,dist_threshold=0.5):\n",
    "#     # if row.score_diff_p_abstractness<=0.05 and row.dist_abstractness>=dist_threshold:\n",
    "#     if row.score_diff_p_abstractness<=0.05 and row.perc_abstractness>=perc_threshold:\n",
    "#         return '+Abstract' if row.score2_abstractness>row.score1_abstractness else '+Concrete'\n",
    "#     return 'Abs~Conc'\n",
    "# def classify_change(row,perc_threshold=70,dist_threshold=0.5):\n",
    "#     if row.is_clean_noiseaware:\n",
    "#         if row.perc_local>=perc_threshold:\n",
    "#         # if row.dist_local>=dist_threshold:\n",
    "#             return '+Changed'\n",
    "#     else:\n",
    "#         return '~Noisy'\n",
    "#     return '-Changed'\n",
    "\n",
    "\n",
    "# def get_dfchange_from_sattelzeit_models(words=None):\n",
    "#     # Load collective difference data\n",
    "#     dfchange=pd.read_csv(FN_CHANGE_RUNS_AVG).set_index('word').sort_values('rank')\n",
    "#     dfchange['class_abs']=dfchange.apply(classify_abstractness,1)\n",
    "#     dfchange['class_change']=dfchange.apply(classify_change,1)\n",
    "#     dfchange['class_signif']=[(x!='Abs~Conc' or y=='+Changed') for x,y in zip(dfchange.class_abs, dfchange.class_change)]\n",
    "#     dfchange['class']=[f'{x} {y}' for x,y in zip(dfchange.class_abs, dfchange.class_change)]\n",
    "    \n",
    "#     # filter?\n",
    "#     return dfchange.sort_values('rank')\n",
    "#     #.query('class_abs!=\"Abs~Conc\" | class_change==\"+Changed\"')\n",
    "#     # return dfchange\n",
    "\n",
    "# def get_dfchange_from_decade_data(fn=FN_VECTOR_SCORES_DIFFMEANS,wide=True):\n",
    "#     idf=pd.read_csv(fn).set_index(['vector','word'])\n",
    "#     if not wide: return idf\n",
    "#     df=None\n",
    "#     for vecname,gdf in idf.groupby('vector'):\n",
    "#         gdf=gdf.reset_index().drop('vector',1).set_index('word')\n",
    "#         gdf.columns=[c+'_'+vecname for c in gdf.columns]\n",
    "#         df=gdf if df is None else df.join(gdf)\n",
    "    \n",
    "#     for c in df.columns:\n",
    "#         if c.startswith('mean_diff_t_abs'):\n",
    "#             df['perc_'+c]=df[c].apply(lambda x: percentileofscore(df[c],x))\n",
    "    \n",
    "#     return df\n",
    "\n",
    "# def get_dfchange(words=None):\n",
    "#     odf=get_dfchange_from_sattelzeit_models().join(get_dfchange_from_decade_data(), how='outer')\n",
    "#     if words: odf=odf.reset_index()[odf.reset_index().word.isin(set(words))].set_index('word')\n",
    "#     return odf\n",
    "\n",
    "# def get_dfchange_simple(dfchange=None, col='mean_diff'):\n",
    "#     if dfchange is None: dfchange=get_dfchange()\n",
    "#     vecs=get_vector_names()\n",
    "#     odf=dfchange[[\n",
    "#         c\n",
    "#         for c in dfchange.columns\n",
    "#         if c.startswith(col+'_')\n",
    "#         and c[len(col)+1:] in set(vecs)\n",
    "#     ]]\n",
    "#     odf.columns=[c[len(col)+1:] for c in odf.columns]\n",
    "#     return odf\n",
    "\n",
    "\n",
    "# def show_change_table(dfchange,gby=['class_abs','class_change']):\n",
    "#     pd.options.display.max_colwidth=100\n",
    "#     dfchange_f=dfchange.query('class_signif==True')\n",
    "#     for gname,gdf in dfchange_f.groupby(gby[0]):\n",
    "#         printm('## '+gname)\n",
    "#         gdfx=pd.DataFrame()\n",
    "#         for gname2,gdf2 in gdf.groupby(gby[1]):\n",
    "#     #         printm('### '+gname2)\n",
    "#             o=', '.join(gdf2.sort_values('rank_local').index)\n",
    "#     #         printm()\n",
    "#             gdfx[gname2]=[o]\n",
    "#         printm(gdfx.to_markdown())\n",
    "#     #     break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# C=None\n",
    "# def get_corpus():\n",
    "#     global C\n",
    "#     if C is None:\n",
    "#         C=lltk.load(CNAME)\n",
    "#     return C\n",
    "\n",
    "# def load_model_row(row,**y):\n",
    "#     return load_model(row.path, row.path_vocab,**y)\n",
    "\n",
    "\n",
    "\n",
    "# #### Misc\n",
    "# def to_z(pivdf,axis=1,progress=False):\n",
    "#     pivdf=pivdf.T if not axis else pivdf\n",
    "#     pivdfz=pd.DataFrame(index=pivdf.index, columns=pivdf.columns)\n",
    "#     for c in (tqdm(pivdf.columns) if progress else pivdf.columns):\n",
    "#         pivdfz[c]=(pivdf[c] - pivdf[c].mean()) / pivdf[c].std()\n",
    "#     return pivdfz.T if not axis else pivdfz\n",
    "\n",
    "\n",
    "# def start_fig(data=None, theme='minimal',text_size=8, figure_size=(8,8), **aesd):\n",
    "#     p9.options.figure_size=figure_size\n",
    "#     p9.options.dpi=600\n",
    "#     fig=p9.ggplot(p9.aes(**aesd), data=data)\n",
    "#     fig+=getattr(p9,f'theme_{theme}')()\n",
    "#     fig+=p9.theme(\n",
    "#         text=p9.element_text(size=text_size),\n",
    "#         plot_background=p9.element_rect(fill='white')\n",
    "#     )\n",
    "#     return fig\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# def get_rate_of_change_data(key='dist_local'):\n",
    "#     df=pd.read_pickle('data/data.semantic_change_over_decades.1run.v3.pkl')\n",
    "#     df['period']=[f'{x[:4]}s->{y[:4]}s' for x,y in zip(df.period1,df.period2)]\n",
    "#     df['period_int1']=[int(y[:4]) for y in df.period1]\n",
    "#     df['period_int2']=[int(y[:4]) for y in df.period2]    \n",
    "#     return df\n",
    "\n",
    "# def get_figdf1_rateofchange(df=None,randomize=False):\n",
    "#     if df is None: df=get_rate_of_change_data()\n",
    "#     pdf=df.groupby(['period','period1','period2']).mean().reset_index()\n",
    "#     if randomize:\n",
    "#         for c in ['period1','period2']:\n",
    "#             pdf[c]=list(pdf[c].sample(frac=1))\n",
    "#     pdf2=pd.DataFrame(pdf).rename(columns=dict(\n",
    "#         period1='period2',\n",
    "#         period2='period1',\n",
    "#     ))\n",
    "#     figdf=pdf.append(pdf2)\n",
    "#     figdf['period_int1']=figdf.period1.apply(lambda x: int(x[:4]))\n",
    "#     figdf['period_int2']=figdf.period2.apply(lambda x: int(x[:4]))\n",
    "#     figdf['perc_local_int']=figdf.dist_local.apply(lambda x: percentileofscore(figdf.dist_local, x)).apply(int)    \n",
    "#     return figdf\n",
    "\n",
    "\n",
    "\n",
    "# DFWAS=None\n",
    "# def get_word_abstractness_scores(cols=['Abs-Conc.Median.C18','Abs-Conc.Median.C19']):\n",
    "#     global DFWAS\n",
    "#     if DFWAS is None:\n",
    "#         DFWAS=get_allnorms()[cols].reset_index().dropna().set_index('word').mean(axis=1)\n",
    "#     return DFWAS\n",
    "\n",
    "\n",
    "# def prdz(y,ystart=1710,yend=3000,ystep=40):\n",
    "#     ln=None\n",
    "#     for n in range(ystart,yend,ystep):\n",
    "#         if ln is None: ln=n\n",
    "#         if y<n: return ln\n",
    "#         ln=n\n",
    "        \n",
    "\n",
    "\n",
    "# def get_novelty_data(ifn=FN_NOVELTY_DATA):\n",
    "#     allres = pd.read_pickle(ifn).query('foote_novelty!=0.0')\n",
    "#     allres['is_signif']=[int(x<0.05 or y<0.05)\n",
    "#                         for x,y in zip(allres.p_peak,allres.p_trough)]\n",
    "#     allres['foote_size']=allres.foote_size.apply(int)\n",
    "#     allres['year']=allres.year.apply(int)\n",
    "#     allres = pd.concat(grp.assign(glen=len(grp)) for i,grp in allres.groupby(['foote_size','year'])).reset_index()\n",
    "#     allres = pd.concat(\n",
    "#         grp.sort_values('year').assign(\n",
    "#             foote_novelty_z=((grp.foote_novelty - grp.foote_novelty.dropna().mean()) / grp.foote_novelty.dropna().std())\n",
    "#         )#.set_index('year').rolling(rolling,min_periods=min_periods).mean()\n",
    "#         for i,grp in allres.groupby('foote_size')\n",
    "#     )\n",
    "#     return allres\n",
    "\n",
    "\n",
    "# C=get_corpus()\n",
    "# logger.remove()\n",
    "# logger.add(sys.stderr, format=\"{message}\", filter='koselleck', level=\"INFO\")\n",
    "# # logger.add(sys.stdout, colorize=True, format=\"<green>{time}</green> <level>{message}</level>\")\n",
    "# def log(*x,**y): logger.info(' '.join(str(xx) for xx in x),**y)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# UPROOT='/Markdown/Drafts/TheGreatAbstraction/figures/'\n",
    "# def upfig(fnfn,uproot=UPROOT):\n",
    "#     ofnfn=os.path.join(uproot,os.path.basename(fnfn))\n",
    "#     cmd=f'dbu upload {fnfn} {ofnfn}'\n",
    "#     os.system(cmd)\n",
    "#     cmd = f'dbu share {ofnfn}'\n",
    "#     os.system(cmd)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# def rsync(ifnfn,ofnfn,flags='-avP'):\n",
    "#     return runcmd(f'rsync {flags} {ifnfn} {ofnfn}')\n",
    "\n",
    "# def _rsync_data_from_ember(obj): return rsync(obj[0], obj[1])\n",
    "# def rsync_data_from_ember(num_proc=1):\n",
    "#     paths_I_want = [\n",
    "#         os.path.join(\n",
    "#             os.path.dirname(path),\n",
    "#             'dists.pkl'\n",
    "#         ).split('/ryan/')[-1] for path in get_model_paths_df(PATH_MODELS_BPO).path\n",
    "#     ]\n",
    "#     objs = [\n",
    "#         (f'ryan@ember:{fn}', os.path.join(os.path.expanduser('~'), fn))\n",
    "#         for fn in paths_I_want\n",
    "#     ]\n",
    "#     objs = [(x,y) for x,y in objs if not os.path.exists(y)]\n",
    "    \n",
    "#     return pmap(_rsync_data_from_ember, objs, num_proc=num_proc, desc='Rsyncing data from ember')\n",
    "# def runcmd(cmd,verbose=False):\n",
    "#     import subprocess\n",
    "#     print('>>',cmd)\n",
    "#     result = subprocess.check_output(cmd.split(), stderr=subprocess.STDOUT).decode()\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def periodize(y,ybin=5):\n",
    "#     y1=y//ybin*ybin\n",
    "#     y2=y1+ybin\n",
    "#     return f'{y1}-{y2}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
