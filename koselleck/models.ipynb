{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (11:05:07) Alles bereit (+0.0s)\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.koselleck import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generated elsewhere..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skipgrams(idir=PATH_SKIPGRAMS_YR,skipgram_n=25, calc_numlines=False):\n",
    "    odf=pd.DataFrame([\n",
    "        {\n",
    "            'corpus':fn.split('.')[2],\n",
    "            'year':int([x for x in fn.split('.') if x.isdigit()][0]),\n",
    "#             'period_end':int([x for x in fn.split('.') if x.isdigit()][-1]),\n",
    "            'path':os.path.join(idir,fn)\n",
    "        }\n",
    "        for fn in os.listdir(idir)\n",
    "        if fn.startswith('data.skipgrams')\n",
    "    ]).sort_values(['corpus','year'])\n",
    "    if calc_numlines:\n",
    "        odf['num_lines']=odf.path.progress_apply(get_numlines)\n",
    "        odf['num_words']=odf['num_lines']*skipgram_n\n",
    "    return odf#.query('1680<=year<1970')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_skipgrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfskip=get_skipgrams(calc_numlines=True)\n",
    "# dfskip['period']=dfskip.year.apply(lambda y: periodize(y,YEARBIN))\n",
    "# dfskip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfskip.groupby('period').num_words.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfskipruns(dfskip,num_runs=10,incl_existing=False):\n",
    "    dfskipruns=pd.concat([\n",
    "        dfskip.assign(run=f'run_{str(i+1).zfill(2)}')\n",
    "        for i in range(num_runs)\n",
    "    ])\n",
    "    dfskipruns['opath']=dfskipruns.apply(lambda row: os.path.join(PATH_MODELS_NEW,row.corpus,row.period,row.run,'model.bin'),1)\n",
    "    dfskipruns['opath_exists']=dfskipruns.opath.apply(lambda x: os.path.exists(x))\n",
    "    if not incl_existing: dfskipruns=dfskipruns[dfskipruns.opath_exists==False]\n",
    "    return dfskipruns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dfskipruns(dfskip,num_runs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_and_save_model(dfskip,nskip=DEFAULT_NUM_SKIP,force=False,vector_size=100,window=10,min_count=5,epochs=10,workers=8,verbose=False):\n",
    "    row=dfskip.iloc[0]\n",
    "    odir=os.path.join(PATH_MODELS_NEW,row.corpus,row.period,row.run)\n",
    "    ofnfn=os.path.join(odir,'model.bin')\n",
    "    if force or not os.path.exists(ofnfn):\n",
    "        ensure_dir_exists(odir)\n",
    "        ss=SkipgramsSamplers(dfskip.path, nskip)\n",
    "        disable_gensim_logging() if not verbose else enable_gensim_logging()\n",
    "        model = Word2Vec(sentences=ss,vector_size=vector_size,window=window,min_count=min_count,epochs=epochs,workers=workers)\n",
    "        model.save(ofnfn)\n",
    "    return pd.DataFrame([{'fnfn':ofnfn}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnfn=gen_and_save_model(get_dfskipruns(dfskip).iloc[:1], force=True).fnfn.iloc[0]\n",
    "# load_model(fnfn).wv.most_similar('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res=pmap_groups(\n",
    "#     gen_and_save_model,\n",
    "#     dfskipruns.groupby(['period','run']),\n",
    "#     num_proc=4,\n",
    "#     kwargs=dict(force=True, nskip=NSKIP_PER_YR)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_models(\n",
    "        ybin=5,\n",
    "        ymin=1680,\n",
    "        ymax=1970,\n",
    "        num_runs=1,\n",
    "        force=False,\n",
    "        nskip_per_yr=NSKIP_PER_YR\n",
    "    ):\n",
    "    dfskip=get_skipgrams(calc_numlines=False).query(f'{ymin}<=year<{ymax}')\n",
    "    dfskip['period']=dfskip.year.apply(lambda y: periodize(y,ybin))\n",
    "    dfskipruns=get_dfskipruns(dfskip, num_runs=num_runs, incl_existing=force)\n",
    "    dfgrps=dfskipruns.groupby(['period','run'])\n",
    "    print(f'Generating {len(dfgrps)} new models over {dfskipruns.period.nunique()} periods and {dfskipruns.run.nunique()} runs')\n",
    "    return pmap_groups(\n",
    "        gen_and_save_model,\n",
    "        dfskipruns.groupby(['period','run']),\n",
    "        num_proc=4,\n",
    "        kwargs=dict(force=force, nskip=nskip_per_yr)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_models(num_runs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            \n",
    "def get_model_paths(model_dir=PATH_MODELS,model_fn='model.bin',vocab_fn='vocab.txt',period_len=None):\n",
    "    \"\"\"\n",
    "    Get all models' paths\n",
    "    \"\"\"\n",
    "    ld=[]\n",
    "    for root,dirs,fns in tqdm(os.walk(model_dir),desc='Scanning directory for models'):\n",
    "        if model_fn in fns:\n",
    "            corpus,period,run=root.split('/')[-3:]\n",
    "            if not 'run_' in run:\n",
    "                corpus,period=root.split('/')[-2:]\n",
    "                run=None\n",
    "            dx={\n",
    "                'corpus':corpus,\n",
    "                'period_start':int(period.split('-')[0]),\n",
    "                'period_end':int(period.split('-')[-1]),\n",
    "                'path':os.path.join(root,model_fn),\n",
    "                'path_vocab':os.path.join(root,vocab_fn)\n",
    "            }\n",
    "            if run is not None: dx['run']=run\n",
    "            if period_len and int(dx['period_end'])-int(dx['period_start'])!=period_len:\n",
    "                continue\n",
    "            ld.append(dx)\n",
    "    return ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1720, 1900, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YMIN,YMAX,YEARBIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathdf_models(period_len=YEARBIN,ymin=YMIN,ymax=YMAX):\n",
    "    pathdf=pd.DataFrame(get_model_paths(PATH_MODELS_BPO, 'model.bin'))#.sort_values(['period_start','run'])\n",
    "    pathdf['period']=[f'{x}-{y}' for x,y in zip(pathdf.period_start, pathdf.period_end)]\n",
    "    pathdf['period_len']=pathdf.period_end - pathdf.period_start\n",
    "    pathdf['qstr']=[\n",
    "        f'vecs({period}_{run.split(\"_\")[-1]})'\n",
    "        for period,run in zip(pathdf.period, pathdf.run)\n",
    "    ]\n",
    "    if period_len: pathdf=pathdf[pathdf.period_len==period_len]\n",
    "    if ymin: pathdf=pathdf[pathdf.period_start>=ymin]\n",
    "    if ymax: pathdf=pathdf[pathdf.period_end<=ymax]\n",
    "    return pathdf[~pathdf.period.isnull()].sort_values('period_start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_pathdf_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_models(ymin=YMIN,ymax=YMAX,ybin=YEARBIN,num_runs=10):\n",
    "    if os.path.exists(FN_DEFAULT_MODEL_PATHS):\n",
    "        odf=read_df(FN_DEFAULT_MODEL_PATHS)\n",
    "    else:\n",
    "        odf=get_pathdf_models(period_len=ybin)\n",
    "        odf.to_pickle(FN_DEFAULT_MODEL_PATHS)\n",
    "    return odf.query(f'{ymin}<=period_start & period_end<={ymax} & run<=\"run_{num_runs:02}\"')\n",
    "    \n",
    "\n",
    "def get_default_periods(**y):\n",
    "    return sorted(list(set(get_default_models(**y).period)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1720-1725',\n",
       " '1725-1730',\n",
       " '1730-1735',\n",
       " '1735-1740',\n",
       " '1740-1745',\n",
       " '1745-1750',\n",
       " '1750-1755',\n",
       " '1755-1760',\n",
       " '1760-1765',\n",
       " '1765-1770',\n",
       " '1770-1775',\n",
       " '1775-1780',\n",
       " '1780-1785',\n",
       " '1785-1790',\n",
       " '1790-1795',\n",
       " '1795-1800',\n",
       " '1800-1805',\n",
       " '1805-1810',\n",
       " '1810-1815',\n",
       " '1815-1820',\n",
       " '1820-1825',\n",
       " '1825-1830',\n",
       " '1830-1835',\n",
       " '1835-1840',\n",
       " '1840-1845',\n",
       " '1845-1850',\n",
       " '1850-1855',\n",
       " '1855-1860',\n",
       " '1860-1865',\n",
       " '1865-1870',\n",
       " '1870-1875',\n",
       " '1875-1880',\n",
       " '1880-1885',\n",
       " '1885-1890',\n",
       " '1890-1895',\n",
       " '1895-1900']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_default_periods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_periods_runs(period_or_periods=None,run_or_runs=None,num_runs=10):\n",
    "    periods=period_or_periods\n",
    "    if periods is None: periods=get_default_periods()\n",
    "    if type(periods)==str: periods=tokenize_fast(periods)\n",
    "    periods=set(periods)\n",
    "    runs=run_or_runs    \n",
    "    if runs is None: runs=list(range(1,num_runs+1))\n",
    "    if type(runs)==int: runs=[runs]\n",
    "    if type(runs)==str: runs=[int(runs)]\n",
    "    runs=set(runs)\n",
    "    return periods,runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'1770-1775', '1780-1785'}, {1, 2, 3, 4, 5, 6, 7, 8, 9, 10})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_periods_runs('1770-1775,1780-1785')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_default_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_default_periods(ymin=1800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(path_model,path_vocab=None,min_count=None,cache_bin=True,cache=True):\n",
    "    global MODEL_CACHE\n",
    "    \n",
    "    if cache and path_model in MODEL_CACHE: return MODEL_CACHE[path_model]\n",
    "    print('Loading',path_model)\n",
    "    model=do_load_model(path_model,path_vocab=path_vocab,min_count=min_count,cache_bin=cache_bin)\n",
    "    return model\n",
    "    \n",
    "def do_load_model(path_model,path_vocab=None,min_count=None,cache_bin=True):\n",
    "#     print('>> loading',path_model)\n",
    "    path_model_bin=path_model.split('.txt')[0]+'.bin' if not path_model.endswith('.bin') else path_model\n",
    "    if os.path.exists(path_model_bin):\n",
    "        model=gensim.models.KeyedVectors.load(path_model_bin,mmap='r')\n",
    "    elif os.path.exists(path_model):\n",
    "        if not path_vocab: path_vocab=os.path.join(os.path.dirname(path_model,'vocab.txt'))\n",
    "        if os.path.exists(path_vocab):\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(path_model,path_vocab)\n",
    "            if min_count: filter_model(model,min_count=min_count)\n",
    "        else:\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(path_model)\n",
    "        if cache_bin:\n",
    "            model.save(path_model_bin)\n",
    "    else:\n",
    "        print('!!??',path_model)\n",
    "        stop\n",
    "        return None\n",
    "#     print(path_model, len(model.wv.key_to_index))\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (11:05:07) Loading /home/ryan/github/koselleck/data1/models/bpo/1805-1810/run_25/model.bin (+0.1s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('folly', 0.7436553835868835),\n",
       " ('humanity', 0.7396243810653687),\n",
       " ('virtuous', 0.7302984595298767),\n",
       " ('social', 0.7297175526618958),\n",
       " ('virtues', 0.7252563834190369),\n",
       " ('wisdom', 0.7209689021110535),\n",
       " ('pride', 0.7133151292800903),\n",
       " ('passions', 0.70967036485672),\n",
       " ('freedom', 0.7070727944374084),\n",
       " ('benevolence', 0.704535186290741)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=load_model('/home/ryan/github/koselleck/data1/models/bpo/1805-1810/run_25/model.bin')\n",
    "m.wv.most_similar('virtue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (11:05:07) Loading /home/ryan/github/koselleck/data1/models/bpo/1945-1950/run_07/model.bin (+0.4s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('elizabeth', 0.719698965549469),\n",
       " ('queen', 0.6907009482383728),\n",
       " ('princess', 0.6652333736419678),\n",
       " (\"victoria's\", 0.574531614780426),\n",
       " ('alexandra', 0.5180464386940002),\n",
       " ('princesses', 0.5009782910346985),\n",
       " ('mary', 0.4933466911315918),\n",
       " ('duke', 0.4914858043193817),\n",
       " ('crown', 0.49019908905029297),\n",
       " ('anne', 0.488145649433136)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=load_model('/home/ryan/github/koselleck/data1/models/bpo/1945-1950/run_07/model.bin')\n",
    "m.wv.most_similar(['king','woman'],['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_models(dfmodels,gby=['period','run']):\n",
    "    o=[]\n",
    "    dfgrp=dfmodels.groupby(gby)\n",
    "    for period,dfg in tqdm(sorted(dfgrp)):#, total=len(dfgrp)):\n",
    "        path=dfg.iloc[-1].path\n",
    "        m=load_model(path)\n",
    "        try:\n",
    "            testvec=m.wv.most_similar(['king','woman'],['man'],topn=25)\n",
    "        except KeyError:\n",
    "            continue\n",
    "        testvec_wl=[x for x,y in testvec]\n",
    "        has_queen='queen' in set(testvec_wl)\n",
    "        odx={\n",
    "            **dict(zip(gby,period)),\n",
    "            'has_queen':has_queen,\n",
    "            'rank_queen':testvec_wl.index('queen') if has_queen else np.nan,\n",
    "            'neighborhood':', '.join(testvec_wl),\n",
    "        }\n",
    "        o+=[odx]\n",
    "#         break\n",
    "    return pd.DataFrame(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfmodels = get_pathdf_models().query('period_len==5')\n",
    "# dftests  = test_models(dfmodels)\n",
    "# dftests.to_csv('../../data/data.model.tests.csv')\n",
    "# dftests.query('has_queen==True').groupby('period').size()\n",
    "# dftests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_veclib_word_data_path(word):\n",
    "    ofn=os.path.join(PATH_DB,'cdists',f'data.cdists.{word}.pkl.gz')\n",
    "    odir=os.path.dirname(ofn)\n",
    "    if not os.path.exists(odir): os.makedirs(odir)\n",
    "    return ofn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ryan/github/koselleck/db/cdists/data.cdists.virtue.pkl.gz'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_new_veclib_word_data_path('virtue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_veclib_word_data(word,progress=True,cache=True,cache_only=False,force=False,remove_old=True,\n",
    "                        periods=None):\n",
    "    if progress: print(f'Loading cdist data for \"{word}\"')\n",
    "    odf=pd.DataFrame()\n",
    "    fnfn=get_new_veclib_word_data_path(word)\n",
    "    oldfnfn=get_old_veclib_word_data_path(word)\n",
    "    if cache and not force and os.path.exists(fnfn):\n",
    "        try:\n",
    "            odf=read_df(fnfn)\n",
    "            if progress: print(f'Finished loading cdist data from pkl for \"{word}\"')\n",
    "        except Exception as e:\n",
    "            print('!!',e)\n",
    "    if not len(odf):\n",
    "        if not os.path.exists(oldfnfn):\n",
    "            if progress: print(f'No file found at {oldfnfn}')\n",
    "        else:\n",
    "            with get_veclib_word(word) as vl:\n",
    "                dfdist=pd.DataFrame(dict(vl.items())).T.rename_axis('period_run_')\n",
    "                dfdist['period_'],dfdist['run_']=zip(*[x.split('_') for x in dfdist.index])\n",
    "                dfdist['run_']=dfdist['run_'].apply(int)\n",
    "                odf=dfdist.reset_index().drop('period_run_',1).set_index(['period_','run_'])\n",
    "                if cache:\n",
    "                    if progress: print(f'Saving dfdist to \"{fnfn}\"')\n",
    "                    odf.to_pickle(fnfn)\n",
    "                    if remove_old and os.path.exists(oldfnfn):\n",
    "                        if progress: print(f'Removing old data from \"{oldfnfn}\"')\n",
    "                        os.remove(oldfnfn)\n",
    "                if progress: print(f'Finished loading cdist data from sqlite for \"{word}\"')\n",
    "    if not len(odf): return odf\n",
    "    odf['word_']=word\n",
    "    odf=odf.reset_index()\n",
    "    \n",
    "    if periods is None: periods=set(get_default_periods())\n",
    "    odf=odf[odf.period_.isin(periods)]\n",
    "    odf=odf.set_index(['word_','period_','run_']).rename_axis(['word','period','run'])\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (11:05:08) Loading cdist data for \"histories\" (+0.4s)\n",
      "[Koselleck] (11:05:08) Finished loading cdist data from pkl for \"histories\" (+0.3s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>a'</th>\n",
       "      <th>a's</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aad</th>\n",
       "      <th>aal</th>\n",
       "      <th>aam</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aas</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoroaster</th>\n",
       "      <th>zos</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zu</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zulus</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>period</th>\n",
       "      <th>run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">histories</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1780-1785</th>\n",
       "      <th>2</th>\n",
       "      <td>1.728527</td>\n",
       "      <td>1.517937</td>\n",
       "      <td>1.706469</td>\n",
       "      <td>1.505782</td>\n",
       "      <td>1.620336</td>\n",
       "      <td>1.681973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.318497</td>\n",
       "      <td>1.733148</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.640306</td>\n",
       "      <td>1.122436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.347848</td>\n",
       "      <td>1.828671</td>\n",
       "      <td>1.905335</td>\n",
       "      <td>1.601725</td>\n",
       "      <td>2.012108</td>\n",
       "      <td>2.415577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.514773</td>\n",
       "      <td>2.028202</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897767</td>\n",
       "      <td>1.622288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.062550</td>\n",
       "      <td>1.714686</td>\n",
       "      <td>2.258954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.807324</td>\n",
       "      <td>1.941981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.489314</td>\n",
       "      <td>1.899359</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.497988</td>\n",
       "      <td>1.410675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.736573</td>\n",
       "      <td>1.800321</td>\n",
       "      <td>1.911046</td>\n",
       "      <td>1.746098</td>\n",
       "      <td>1.874663</td>\n",
       "      <td>2.108638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.873124</td>\n",
       "      <td>1.882235</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.793693</td>\n",
       "      <td>1.223120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.178246</td>\n",
       "      <td>1.901612</td>\n",
       "      <td>2.201326</td>\n",
       "      <td>1.856099</td>\n",
       "      <td>2.087203</td>\n",
       "      <td>1.823636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.535926</td>\n",
       "      <td>2.307930</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.878862</td>\n",
       "      <td>1.641602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1895-1900</th>\n",
       "      <th>6</th>\n",
       "      <td>1.896813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.792559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.201605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.084911</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.725056</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.270421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.721304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.545514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.223810</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.656098</td>\n",
       "      <td>2.077523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.382183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.914793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.539141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.028859</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.965047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.133486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.548652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.615873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.159049</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.880041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.195957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.028525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.790732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.380351</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.484219</td>\n",
       "      <td>2.110829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows Ã— 27332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               a'       a's        aa       aaa       aad  \\\n",
       "word      period    run                                                     \n",
       "histories 1780-1785 2    1.728527  1.517937  1.706469  1.505782  1.620336   \n",
       "                    4    2.347848  1.828671  1.905335  1.601725  2.012108   \n",
       "                    3    2.062550  1.714686  2.258954       NaN  1.807324   \n",
       "                    5    1.736573  1.800321  1.911046  1.746098  1.874663   \n",
       "                    6    2.178246  1.901612  2.201326  1.856099  2.087203   \n",
       "...                           ...       ...       ...       ...       ...   \n",
       "          1895-1900 6    1.896813       NaN  1.792559       NaN  1.201605   \n",
       "                    7    2.270421       NaN  1.721304       NaN  1.545514   \n",
       "                    8    2.382183       NaN  1.914793       NaN  1.539141   \n",
       "                    9    2.133486       NaN  1.548652       NaN  1.615873   \n",
       "                    10   2.195957       NaN  2.028525       NaN  1.790732   \n",
       "\n",
       "                              aal  aam  aaron       aas        ab  ...  zoom  \\\n",
       "word      period    run                                            ...         \n",
       "histories 1780-1785 2    1.681973  NaN    NaN  1.318497  1.733148  ...   NaN   \n",
       "                    4    2.415577  NaN    NaN  1.514773  2.028202  ...   NaN   \n",
       "                    3    1.941981  NaN    NaN  1.489314  1.899359  ...   NaN   \n",
       "                    5    2.108638  NaN    NaN  1.873124  1.882235  ...   NaN   \n",
       "                    6    1.823636  NaN    NaN  1.535926  2.307930  ...   NaN   \n",
       "...                           ...  ...    ...       ...       ...  ...   ...   \n",
       "          1895-1900 6         NaN  NaN    NaN       NaN  2.084911  ...   NaN   \n",
       "                    7         NaN  NaN    NaN       NaN  2.223810  ...   NaN   \n",
       "                    8         NaN  NaN    NaN       NaN  2.028859  ...   NaN   \n",
       "                    9         NaN  NaN    NaN       NaN  2.159049  ...   NaN   \n",
       "                    10        NaN  NaN    NaN       NaN  2.380351  ...   NaN   \n",
       "\n",
       "                         zoroaster  zos        zr        zs        zu  zulu  \\\n",
       "word      period    run                                                       \n",
       "histories 1780-1785 2          NaN  NaN  1.640306  1.122436       NaN   NaN   \n",
       "                    4          NaN  NaN  1.897767  1.622288       NaN   NaN   \n",
       "                    3          NaN  NaN  1.497988  1.410675       NaN   NaN   \n",
       "                    5          NaN  NaN  1.793693  1.223120       NaN   NaN   \n",
       "                    6          NaN  NaN  1.878862  1.641602       NaN   NaN   \n",
       "...                            ...  ...       ...       ...       ...   ...   \n",
       "          1895-1900 6          NaN  NaN       NaN       NaN  1.725056   NaN   \n",
       "                    7          NaN  NaN       NaN  1.656098  2.077523   NaN   \n",
       "                    8          NaN  NaN       NaN       NaN  1.965047   NaN   \n",
       "                    9          NaN  NaN       NaN       NaN  1.880041   NaN   \n",
       "                    10         NaN  NaN       NaN  1.484219  2.110829   NaN   \n",
       "\n",
       "                         zulus  zurich  zz  \n",
       "word      period    run                     \n",
       "histories 1780-1785 2      NaN     NaN NaN  \n",
       "                    4      NaN     NaN NaN  \n",
       "                    3      NaN     NaN NaN  \n",
       "                    5      NaN     NaN NaN  \n",
       "                    6      NaN     NaN NaN  \n",
       "...                        ...     ...  ..  \n",
       "          1895-1900 6      NaN     NaN NaN  \n",
       "                    7      NaN     NaN NaN  \n",
       "                    8      NaN     NaN NaN  \n",
       "                    9      NaN     NaN NaN  \n",
       "                    10     NaN     NaN NaN  \n",
       "\n",
       "[343 rows x 27332 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdist=get_veclib_word_data('histories',force=False,remove_old=False,cache_only=False)\n",
    "dfdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_words_in_sqlite_data():\n",
    "    fns=os.listdir(os.path.join(PATH_DB,'wvecs'))\n",
    "    words=[fn.split('.sqlite')[0].split('.')[-1] for fn in fns]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words=get_all_words_in_sqlite_data()\n",
    "# len(words),random.sample(words,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_veclib_word_data_(objd): return get_veclib_word_data(**objd)\n",
    "def reformat_all_sqlite_data(words=None,lim=None,num_proc=1,remove_old=True):\n",
    "    words=get_all_words_in_sqlite_data()[:lim] if words is None else list(words)[:lim]\n",
    "    return pmap(\n",
    "        _get_veclib_word_data_,\n",
    "        [dict(word=word,progress=False,cache=True,force=True,remove_old=remove_old,\n",
    "              cache_only=True) for word in words],\n",
    "        num_proc=num_proc,\n",
    "        desc='Reformatting old sqlite data into pkl files',\n",
    "        use_threads=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words=get_valid_words()\n",
    "# random.shuffle(words)\n",
    "# res=reformat_all_sqlite_data(words,lim=None,num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
