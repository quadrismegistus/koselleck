{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.koselleck import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_foote(quart=FOOTE_W):\n",
    "    tophalf = [-1] * quart + [1] * quart\n",
    "    bottomhalf = [1] * quart + [-1] * quart\n",
    "    foote = list()\n",
    "    for i in range(quart):\n",
    "        foote.append(tophalf)\n",
    "    for i in range(quart):\n",
    "        foote.append(bottomhalf)\n",
    "    foote = np.array(foote)\n",
    "    return foote\n",
    "\n",
    "def foote_novelty(distdf, foote_size=5):\n",
    "    foote=make_foote(foote_size)\n",
    "    distmat = distdf.values if type(distdf)==pd.DataFrame else distdf\n",
    "    \n",
    "    axis1, axis2 = distmat.shape\n",
    "    assert axis1 == axis2\n",
    "    distsize = axis1\n",
    "    axis1, axis2 = foote.shape\n",
    "    assert axis1 == axis2\n",
    "    halfwidth = axis1 / 2\n",
    "    novelties = []\n",
    "    for i in range(distsize):\n",
    "        start = int(i - halfwidth)\n",
    "        end = int(i + halfwidth)\n",
    "        if start < 0 or end > (distsize - 1):\n",
    "            novelties.append(0)\n",
    "        else:\n",
    "            novelties.append(np.sum(foote * distmat[start: end, start: end]))\n",
    "    return novelties\n",
    "\n",
    "def getyears():\n",
    "    years=list(d.columns)\n",
    "    return years\n",
    "\n",
    "\n",
    "def diagonal_permute(d):\n",
    "    newmat = np.zeros(d.shape)\n",
    "    \n",
    "    # We create one randomly-permuted list of integers called \"translate\"\n",
    "    # that is going to be used for the whole matrix.\n",
    "    \n",
    "    xlen,ylen=d.shape\n",
    "    translate = [i for i in range(xlen)]\n",
    "    random.shuffle(translate)\n",
    "    \n",
    "    # Because distances matrices are symmetrical, we're going to be doing\n",
    "    # two diagonals at once each time. We only need one set of values\n",
    "    # (because symmetrical) but we need two sets of indices in the original\n",
    "    # matrix so we know where to put the values back when we're done permuting\n",
    "    # them.\n",
    "    \n",
    "    for i in range(0, xlen):\n",
    "        indices1 = []\n",
    "        indices2 = []\n",
    "        values = []\n",
    "        for x in range(xlen):\n",
    "            y1 = x + i\n",
    "            y2 = x - i\n",
    "            if y1 >= 0 and y1 < ylen:\n",
    "                values.append(d[x, y1])\n",
    "                indices1.append((x, y1))\n",
    "            if y2 >= 0 and y2 < ylen:\n",
    "                indices2.append((x, y2))\n",
    "        \n",
    "        # Okay, for each diagonal, we permute the values.\n",
    "        # We'll store the permuted values in newvalues.\n",
    "        # We also check to see how many values we have,\n",
    "        # so we can randomly select values if needed.\n",
    "        \n",
    "        newvalues = []\n",
    "        lenvals = len(values)\n",
    "        vallist = [i for i in range(lenvals)]\n",
    "        \n",
    "        for indexes, value in zip(indices1, values):\n",
    "            x, y = indexes\n",
    "            \n",
    "            xposition = translate[x]\n",
    "            yposition = translate[y]\n",
    "            \n",
    "            # We're going to key the randomization to the x, y\n",
    "            # values for each point, insofar as that's possible.\n",
    "            # Doing this will ensure that specific horizontal and\n",
    "            # vertical lines preserve the dependence relations in\n",
    "            # the original matrix.\n",
    "            \n",
    "            # But the way we're doing this is to use the permuted\n",
    "            # x (or y) values to select an index in our list of\n",
    "            # values in the present diagonal, and that's only possible\n",
    "            # if the list is long enough to permit it. So we check:\n",
    "            \n",
    "            if xposition < 0 and yposition < 0:\n",
    "                position = random.choice(vallist)\n",
    "            elif xposition >= lenvals and yposition >= lenvals:\n",
    "                position = random.choice(vallist)\n",
    "            elif xposition < 0:\n",
    "                position = yposition\n",
    "            elif yposition < 0:\n",
    "                position = xposition\n",
    "            elif xposition >= lenvals:\n",
    "                position = yposition\n",
    "            elif yposition >= lenvals:\n",
    "                position = xposition\n",
    "            else:\n",
    "                position = random.choice([xposition, yposition])\n",
    "                # If either x or y could be used as an index, we\n",
    "                # select randomly.\n",
    "            \n",
    "            # Whatever index was chosen, we use it to select a value\n",
    "            # from our diagonal. \n",
    "            \n",
    "            newvalues.append(values[position])\n",
    "            \n",
    "        values = newvalues\n",
    "        \n",
    "        # Now we lay down (both versions of) the diagonal in the\n",
    "        # new matrix.\n",
    "        \n",
    "        for idxtuple1, idxtuple2, value in zip(indices1, indices2, values):\n",
    "            x, y = idxtuple1\n",
    "            newmat[x, y] = value\n",
    "            x, y = idxtuple2\n",
    "            newmat[x, y] = value\n",
    "    \n",
    "    return newmat\n",
    "\n",
    "def zeroless(sequence):\n",
    "    newseq = []\n",
    "    for element in sequence:\n",
    "        if element > 0.01:\n",
    "            newseq.append(element)\n",
    "    return newseq\n",
    "\n",
    "def permute_test(distmatrix, foote_size=FOOTE_W, num_runs=100):\n",
    "    actual_novelties = foote_novelty(distmatrix, foote_size)    \n",
    "    permuted_peaks = []\n",
    "    permuted_troughs = []\n",
    "    xlen,ylen=distmatrix.shape\n",
    "    for i in range(num_runs):\n",
    "        randdist = diagonal_permute(distmatrix)\n",
    "        nov = foote_novelty(randdist, foote_size)\n",
    "        nov = zeroless(nov)\n",
    "        permuted_peaks.append(np.max(nov))\n",
    "        permuted_troughs.append(np.min(nov))\n",
    "    permuted_peaks.sort(reverse = True)\n",
    "    permuted_troughs.sort(reverse = True)\n",
    "    significance_peak = np.ones(len(actual_novelties))\n",
    "    significance_trough = np.ones(len(actual_novelties))\n",
    "    for idx, novelty in enumerate(actual_novelties):\n",
    "        ptop=[i for i,x in enumerate(permuted_peaks) if x and x < novelty]\n",
    "        ptop=ptop[0]/num_runs if ptop else 1\n",
    "        pbot=[i for i,x in enumerate(permuted_troughs) if x and x > novelty]\n",
    "        pbot=pbot[-1]/num_runs if pbot else 1\n",
    "        significance_peak[idx]=ptop\n",
    "        significance_trough[idx]=pbot\n",
    "        \n",
    "        \n",
    "    \n",
    "    return actual_novelties, significance_peak, significance_trough\n",
    "\n",
    "def colored_segments(novelties, significance, yrwidth=1,min_year=1700):\n",
    "    x = []\n",
    "    y = []\n",
    "    t = []\n",
    "    idx = 0\n",
    "    for nov, sig in zip(novelties, significance):\n",
    "        if nov > 1:\n",
    "            x.append((idx*yrwidth) + min_year)\n",
    "            y.append(nov)\n",
    "            t.append(sig)\n",
    "        idx += 1\n",
    "        \n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    t = np.array(t)\n",
    "    \n",
    "    points = np.array([x,y]).transpose().reshape(-1,1,2)\n",
    "    segs = np.concatenate([points[:-1],points[1:]],axis=1)\n",
    "    lc = LineCollection(segs, cmap=plt.get_cmap('jet'))\n",
    "    lc.set_array(t)\n",
    "    \n",
    "    return lc, x, y\n",
    "    \n",
    "    \n",
    "def test_novelty(distdf, foote_sizes=None, num_runs=100):\n",
    "    if not foote_sizes: foote_sizes=range(FOOTE_W-3, FOOTE_W+2)\n",
    "    dq=distdf.fillna(0).values\n",
    "    o=[]\n",
    "    for fs in foote_sizes:\n",
    "        try:\n",
    "            novelties, significance_peak, significance_trough = permute_test(dq, foote_size=fs, num_runs=num_runs)\n",
    "        except ValueError as e:\n",
    "#             print('!!',e,'!!')\n",
    "#             print(distdf)\n",
    "            continue\n",
    "        for year,nov,sigp,sigt in zip(distdf.columns, novelties, significance_peak, significance_trough):\n",
    "            odx={\n",
    "                'period':year,\n",
    "                'foote_novelty':nov,\n",
    "                'foote_size':fs,\n",
    "                'p_peak':sigp,\n",
    "                'p_trough':sigt,\n",
    "            }\n",
    "            o.append(odx)\n",
    "    return pd.DataFrame(o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nov(word_or_words,\n",
    "        num_proc=1, progress=True,\n",
    "        ybin=YBIN_DISTMAT,ymin=YMIN_DISTMAT,ymax=YMAX_DISTMAT,k=K,\n",
    "        force=False,cache_only=False,\n",
    "        **distmat_opts):\n",
    "    #print(f'nov({word_or_words})')\n",
    "    objs_todo=objs=[\n",
    "        dict(\n",
    "            word=w,\n",
    "            qstr=f'{w}/{ymin}-{ymax}_by{ybin}/k={k}',\n",
    "            progress=False,\n",
    "            ybin=ybin,ymax=ymax,ymin=ymin,k=k,\n",
    "            **distmat_opts\n",
    "        ) for w in to_words(word_or_words)\n",
    "    ]\n",
    "    objs_done={}    \n",
    "    if not force:\n",
    "        with get_db('nov',mode='r') as db:\n",
    "            objs_done=dict(\n",
    "                (\n",
    "                    x['qstr'],\n",
    "                    db.get(x['qstr']) if not cache_only else pd.DataFrame(),\n",
    "                )\n",
    "                for x in objs\n",
    "                if x['qstr'] in db\n",
    "            )\n",
    "            objs_todo=[x for x in objs if x['qstr'] not in objs_done]\n",
    "    if len(objs_todo):\n",
    "        objs_done_now={}\n",
    "        iterr=pmap_iter(\n",
    "            nov_word_,\n",
    "            objs_todo,\n",
    "            num_proc=num_proc,\n",
    "            progress=progress if len(objs_todo)>1 else False\n",
    "        )\n",
    "        with get_db('nov',mode='c') as db:\n",
    "            for i,odf in enumerate(iterr):\n",
    "                if odf is not None and len(odf):\n",
    "                    qstr=odf.iloc[0].qstr\n",
    "                    odf=odf.drop('qstr',1)\n",
    "                    #objs_done_now[qstr]=odf\n",
    "                    db[qstr]=odf\n",
    "                    objs_done[qstr]=odf if not cache_only else pd.DataFrame()\n",
    "                if i and not i%10: db.commit()\n",
    "            db.commit()\n",
    "    return pd.concat(list(objs_done.values()))# if not cache_only else None\n",
    "    \n",
    "        \n",
    "def nov_word(word,qstr=None,**distmat_opts):\n",
    "    try:\n",
    "        odf=test_novelty(distmat(word, **distmat_opts)).assign(\n",
    "            word=word\n",
    "        ).query('foote_novelty!=0').set_index(['word','period'])\n",
    "        if qstr: odf=odf.assign(qstr=qstr)\n",
    "        return odf\n",
    "    except Exception as e:\n",
    "#         print('!!',e)\n",
    "        return pd.DataFrame()\n",
    "def nov_word_(obj): return nov_word(**obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_novelty_data(words=None,num_proc=4):\n",
    "    if not words: words=get_valid_words()\n",
    "    nov(words, num_proc=num_proc, cache_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOV_DATA_SUMM=None\n",
    "# def get_nov_data_summarised(foote_size=5,force=True,key_all='_summary_'):\n",
    "#     global NOV_DATA_SUMM\n",
    "#     if not force and NOV_DATA_SUMM is not None: return NOV_DATA_SUMM\n",
    "\n",
    "#     with get_db('nov','r') as db:\n",
    "#         if key_all in db: return db[key_all]\n",
    "        \n",
    "#         l=[]\n",
    "#         for qstr,qwdf in tqdm(db.items(), total=len(db)):\n",
    "#             for fs,wdf in qwdf.groupby('foote_size'):\n",
    "#                 wdf=wdf.reset_index().sort_values('period')#.query(f'foote_size=={foote_size}')\n",
    "\n",
    "# #                 display(wdf)\n",
    "#                 wdf['period_int']=[int(p[:4]) for p in wdf['period']]\n",
    "#                 wdf['is_signif']=wdf['p_peak']<0.05\n",
    "#                 wdf_signif=wdf[wdf.is_signif==True]\n",
    "#                 changepoint=wdf_signif.iloc[0].period_int if len(wdf_signif) else np.nan\n",
    "#                 changepoint_avg=wdf_signif.period_int.median() if len(wdf_signif) else np.nan\n",
    "\n",
    "#                 num_signif=len(wdf_signif)\n",
    "\n",
    "#                 word,prdstr,atrstr=qstr.split('/')\n",
    "#                 yminymax,ybin=prdstr.split('_')\n",
    "#                 ybin=ybin.replace('by','')\n",
    "#                 kstr=atrstr.split('k=')[-1]\n",
    "#                 ymin,ymax=yminymax.split('-')\n",
    "#                 dx1=dict(\n",
    "#                     word=word,\n",
    "#                     changepoint_first=changepoint,\n",
    "#                     changepoint_avg=changepoint_avg,\n",
    "\n",
    "#                     num_signif_periods=num_signif,\n",
    "#                     num_periods=len(wdf),\n",
    "\n",
    "#                     ymin=ymin,\n",
    "#                     ymax=ymax,\n",
    "#                     ybin=ybin,\n",
    "#                     k=kstr\n",
    "#                 )\n",
    "#                 dx={\n",
    "#                     **dict((k+'_signif',v) for k,v in wdf_signif.mean().items()),\n",
    "#                     **dict(wdf.mean()),\n",
    "#                     **dx1,\n",
    "#                 }\n",
    "#                 l+=[dx]\n",
    "#         odf=pd.DataFrame(l).sort_values('foote_novelty',ascending=False)\n",
    "#         odf=odf[~odf.foote_novelty.isna()]\n",
    "#         odf=odf.set_index('word').drop(['word_signif','period_signif'],1)\n",
    "#         odf=odf[[c for c in sorted(odf.columns)]]\n",
    "#         NOV_DATA_SUMM=odf\n",
    "#         with get_db('nov','w') as db: db[key_all]=odf\n",
    "#     return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_all_novelty_scores??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnovdata = get_nov_data_summarised(foote_size=6)\n",
    "# dfnovdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnovdata.loc[set(dfnovdata.index) & set(get_keywords())]#.num_periods.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnovdata.loc[['culture','station','train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdf=dfnovdata[dfnovdata.num_periods==dfnovdata.num_periods.max()]\n",
    "# qdf=qdf.query('num_signif_periods>2 & changepoint_avg>=1760')\n",
    "# qdf=qdf.loc[[w for w in qdf.index if len(w)>4]]\n",
    "# qdf.sort_values('foote_novelty_signif',ascending=False).head(25)#.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnovdata.loc[['culture','labour','liberty','station']]#.num_periods.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_distmat(distmat('merchant'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,g in nbr('embroidered').groupby('period'):\n",
    "#     print(i)\n",
    "#     display(g.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFALLNOV={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novelty(words,ybin=YBIN_DISTMAT,\n",
    "                min_foote_size=FOOTE_W,max_foote_size=FOOTE_W,**nov_attrs):\n",
    "#     global DFALLNOV\n",
    "    wordkey=str(tuple([w for w in sorted(to_words(words))] + [ybin, min_foote_size, max_foote_size]))\n",
    "    \n",
    "    with get_db('nov','r') as db:\n",
    "        if wordkey in db: return db[wordkey]\n",
    "    odf=nov(words,ybin=ybin,force=False,progress=True,**nov_attrs).query(f'{min_foote_size}<=foote_size<={max_foote_size}')\n",
    "    odf=pd.concat(\n",
    "        grp.assign(foote_novelty_z=(grp.foote_novelty - grp.foote_novelty.mean()) / grp.foote_novelty.std())\n",
    "        for i,grp in odf.groupby('foote_size')\n",
    "    )\n",
    "    odf=odf.reset_index()\n",
    "    odf['period_str']=odf['period']\n",
    "    odf['period']=odf['period'].apply(lambda x: int(x[:4]))\n",
    "    odf['is_signif']=odf['p_peak']<=0.05\n",
    "    #DFALLNOV[wordkey]=odf\n",
    "    with get_db('nov','w') as db: db[wordkey]=odf\n",
    "    return odf\n",
    "\n",
    "def get_all_novelty_scores(words=None,**attrs):\n",
    "    dfallnov=get_novelty(get_valid_words() if not words else words,**attrs).sort_values('foote_novelty')\n",
    "    dfallnov['period_int']=dfallnov['period'].apply(int)\n",
    "    return dfallnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping nov_word_() [x1]: 100%|██████████| 178/178 [00:07<00:00, 24.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>period</th>\n",
       "      <th>foote_novelty</th>\n",
       "      <th>foote_size</th>\n",
       "      <th>p_peak</th>\n",
       "      <th>p_trough</th>\n",
       "      <th>foote_novelty_z</th>\n",
       "      <th>period_str</th>\n",
       "      <th>is_signif</th>\n",
       "      <th>period_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>337255</th>\n",
       "      <td>shopkeeper</td>\n",
       "      <td>1810</td>\n",
       "      <td>-0.956722</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-3.428777</td>\n",
       "      <td>1810-1815</td>\n",
       "      <td>False</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992107</th>\n",
       "      <td>caverns</td>\n",
       "      <td>1795</td>\n",
       "      <td>-0.454544</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-1.958270</td>\n",
       "      <td>1795-1800</td>\n",
       "      <td>False</td>\n",
       "      <td>1795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108899</th>\n",
       "      <td>flowing</td>\n",
       "      <td>1840</td>\n",
       "      <td>-0.454065</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-2.434111</td>\n",
       "      <td>1840-1845</td>\n",
       "      <td>False</td>\n",
       "      <td>1840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022598</th>\n",
       "      <td>shopkeeper</td>\n",
       "      <td>1810</td>\n",
       "      <td>-0.437863</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-1.943349</td>\n",
       "      <td>1810-1815</td>\n",
       "      <td>False</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695250</th>\n",
       "      <td>shopkeeper</td>\n",
       "      <td>1810</td>\n",
       "      <td>-0.407635</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-2.081623</td>\n",
       "      <td>1810-1815</td>\n",
       "      <td>False</td>\n",
       "      <td>1810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883781</th>\n",
       "      <td>foil</td>\n",
       "      <td>1815</td>\n",
       "      <td>19.230101</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>15.650262</td>\n",
       "      <td>1815-1820</td>\n",
       "      <td>True</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799233</th>\n",
       "      <td>crystal</td>\n",
       "      <td>1850</td>\n",
       "      <td>19.635120</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.012565</td>\n",
       "      <td>1850-1855</td>\n",
       "      <td>True</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960902</th>\n",
       "      <td>fins</td>\n",
       "      <td>1815</td>\n",
       "      <td>20.522430</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>16.806291</td>\n",
       "      <td>1815-1820</td>\n",
       "      <td>True</td>\n",
       "      <td>1815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836294</th>\n",
       "      <td>ragged</td>\n",
       "      <td>1845</td>\n",
       "      <td>21.243869</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.451641</td>\n",
       "      <td>1845-1850</td>\n",
       "      <td>True</td>\n",
       "      <td>1845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742101</th>\n",
       "      <td>cloth</td>\n",
       "      <td>1830</td>\n",
       "      <td>21.480622</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>17.663424</td>\n",
       "      <td>1830-1835</td>\n",
       "      <td>True</td>\n",
       "      <td>1830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061032 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  period  foote_novelty  foote_size  p_peak  p_trough  \\\n",
       "337255   shopkeeper    1810      -0.956722           4     1.0      0.99   \n",
       "992107      caverns    1795      -0.454544           6     1.0      0.99   \n",
       "108899      flowing    1840      -0.454065           4     1.0      0.99   \n",
       "1022598  shopkeeper    1810      -0.437863           6     1.0      0.99   \n",
       "695250   shopkeeper    1810      -0.407635           5     1.0      0.99   \n",
       "...             ...     ...            ...         ...     ...       ...   \n",
       "883781         foil    1815      19.230101           6     0.0      1.00   \n",
       "799233      crystal    1850      19.635120           6     0.0      1.00   \n",
       "960902         fins    1815      20.522430           6     0.0      1.00   \n",
       "836294       ragged    1845      21.243869           6     0.0      1.00   \n",
       "742101        cloth    1830      21.480622           6     0.0      1.00   \n",
       "\n",
       "         foote_novelty_z period_str  is_signif  period_int  \n",
       "337255         -3.428777  1810-1815      False        1810  \n",
       "992107         -1.958270  1795-1800      False        1795  \n",
       "108899         -2.434111  1840-1845      False        1840  \n",
       "1022598        -1.943349  1810-1815      False        1810  \n",
       "695250         -2.081623  1810-1815      False        1810  \n",
       "...                  ...        ...        ...         ...  \n",
       "883781         15.650262  1815-1820       True        1815  \n",
       "799233         16.012565  1850-1855       True        1850  \n",
       "960902         16.806291  1815-1820       True        1815  \n",
       "836294         17.451641  1845-1850       True        1845  \n",
       "742101         17.663424  1830-1835       True        1830  \n",
       "\n",
       "[1061032 rows x 10 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfallnov=get_all_novelty_scores(min_foote_size=4,max_foote_size=6)\n",
    "dfallnov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfallnov.groupby('word').size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfallnov[dfallnov.word=='special']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>period</th>\n",
       "      <th>foote_novelty</th>\n",
       "      <th>foote_size</th>\n",
       "      <th>p_peak</th>\n",
       "      <th>p_trough</th>\n",
       "      <th>foote_novelty_z</th>\n",
       "      <th>period_str</th>\n",
       "      <th>is_signif</th>\n",
       "      <th>period_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60504</th>\n",
       "      <td>culture</td>\n",
       "      <td>1825</td>\n",
       "      <td>3.290524</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.757745</td>\n",
       "      <td>1825-1830</td>\n",
       "      <td>True</td>\n",
       "      <td>1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60503</th>\n",
       "      <td>culture</td>\n",
       "      <td>1820</td>\n",
       "      <td>3.542621</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.087636</td>\n",
       "      <td>1820-1825</td>\n",
       "      <td>True</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  period  foote_novelty  foote_size  p_peak  p_trough  \\\n",
       "60504  culture    1825       3.290524           5    0.01       1.0   \n",
       "60503  culture    1820       3.542621           5    0.00       1.0   \n",
       "\n",
       "       foote_novelty_z period_str  is_signif  period_int  \n",
       "60504         2.757745  1825-1830       True        1825  \n",
       "60503         3.087636  1820-1825       True        1820  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf=get_all_novelty_scores().query(f'p_peak<=.01')\n",
    "odf[odf.word=='culture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_signif_novelty_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signif_novelty_scores(p_peak=0.01,min_peaks=2,force=False,consecutive_peaks=True, ybin=YBIN_DISTMAT,\n",
    "                              min_foote_size=FOOTE_W, max_foote_size=FOOTE_W, **atr):\n",
    "    key=str((p_peak,min_peaks,consecutive_peaks,ybin,min_foote_size,max_foote_size))\n",
    "    if not force:\n",
    "        with get_db('nov','r') as db:\n",
    "            if key in db: return db[key]\n",
    "    \n",
    "    odf=get_all_novelty_scores(min_foote_size=min_foote_size, max_foote_size=max_foote_size, **atr).query(f'p_peak<={p_peak}')\n",
    "    odf=pd.concat(\n",
    "        grp.assign(word_num_peaks=len(grp))\n",
    "        for i,grp in tqdm(odf.groupby(['word','foote_size']))\n",
    "    )\n",
    "    if min_peaks: odf=odf[odf.word_num_peaks>=min_peaks]\n",
    "    if consecutive_peaks and min_peaks>1:\n",
    "        l=[]\n",
    "        for (wx,fs),g in odf.groupby(['word','foote_size']):\n",
    "            g=g.sort_values('period_int')\n",
    "            for i in range(1,len(g)):\n",
    "                prev=g.iloc[i-1]\n",
    "                this=g.iloc[i]\n",
    "                if int(prev.period)+ybin != int(this.period):\n",
    "                    break\n",
    "            else:\n",
    "                l+=[g]\n",
    "        odf=pd.concat(l) if len(l) else pd.DataFrame()\n",
    "    if len(odf):\n",
    "        odf=odf.sort_values(\n",
    "            'foote_novelty_z',\n",
    "            ascending=False\n",
    "        )#.reset_index()\n",
    "    with get_db('nov','w') as db: db[key]=odf    \n",
    "    return odf\n",
    "\n",
    "def get_signif_novelty_words(**opts):\n",
    "    df=get_all_novelty_scores()\n",
    "    dfsign=get_signif_novelty_scores(**opts)\n",
    "    signwset=set(dfsign.word)\n",
    "    return signwset\n",
    "    o=[\n",
    "        w for w in \n",
    "        df.groupby('word').mean().sort_values(\n",
    "            'foote_novelty',ascending=False\n",
    "        ).index\n",
    "        if w in signwset\n",
    "    ]\n",
    "    return o\n",
    "\n",
    "def get_signif_novelty_scores_summary(**opts):\n",
    "    df=get_signif_novelty_scores(**opts)\n",
    "    df=pd.concat(\n",
    "        grp.assign(\n",
    "            changepoint=grp.period_int.min(),\n",
    "            changepoint_avg=grp.period_int.median(),\n",
    "        )\n",
    "        for i,grp in df.groupby('word')\n",
    "    )\n",
    "    df=df.groupby('word').mean()\n",
    "    df['nov_rank']=df.foote_novelty.rank(ascending=False)\n",
    "    df=df.sort_values('nov_rank')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11103/11103 [00:03<00:00, 3002.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>period</th>\n",
       "      <th>foote_novelty</th>\n",
       "      <th>foote_size</th>\n",
       "      <th>p_peak</th>\n",
       "      <th>p_trough</th>\n",
       "      <th>foote_novelty_z</th>\n",
       "      <th>period_str</th>\n",
       "      <th>is_signif</th>\n",
       "      <th>period_int</th>\n",
       "      <th>word_num_peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>491047</th>\n",
       "      <td>ragged</td>\n",
       "      <td>1845</td>\n",
       "      <td>15.009504</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.093063</td>\n",
       "      <td>1845-1850</td>\n",
       "      <td>True</td>\n",
       "      <td>1845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>sound</td>\n",
       "      <td>1800</td>\n",
       "      <td>9.766796</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.791078</td>\n",
       "      <td>1800-1805</td>\n",
       "      <td>True</td>\n",
       "      <td>1800</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742101</th>\n",
       "      <td>cloth</td>\n",
       "      <td>1830</td>\n",
       "      <td>21.480622</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.663424</td>\n",
       "      <td>1830-1835</td>\n",
       "      <td>True</td>\n",
       "      <td>1830</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627159</th>\n",
       "      <td>fins</td>\n",
       "      <td>1815</td>\n",
       "      <td>14.552565</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.495118</td>\n",
       "      <td>1815-1820</td>\n",
       "      <td>True</td>\n",
       "      <td>1815</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836294</th>\n",
       "      <td>ragged</td>\n",
       "      <td>1845</td>\n",
       "      <td>21.243869</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.451641</td>\n",
       "      <td>1845-1850</td>\n",
       "      <td>True</td>\n",
       "      <td>1845</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739503</th>\n",
       "      <td>doubt</td>\n",
       "      <td>1790</td>\n",
       "      <td>0.878696</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.765645</td>\n",
       "      <td>1790-1795</td>\n",
       "      <td>True</td>\n",
       "      <td>1790</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411125</th>\n",
       "      <td>serve</td>\n",
       "      <td>1800</td>\n",
       "      <td>0.592346</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.773059</td>\n",
       "      <td>1800-1805</td>\n",
       "      <td>True</td>\n",
       "      <td>1800</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411126</th>\n",
       "      <td>serve</td>\n",
       "      <td>1805</td>\n",
       "      <td>0.590404</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.775601</td>\n",
       "      <td>1805-1810</td>\n",
       "      <td>True</td>\n",
       "      <td>1805</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386021</th>\n",
       "      <td>doubt</td>\n",
       "      <td>1795</td>\n",
       "      <td>0.577880</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.791989</td>\n",
       "      <td>1795-1800</td>\n",
       "      <td>True</td>\n",
       "      <td>1795</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386020</th>\n",
       "      <td>doubt</td>\n",
       "      <td>1790</td>\n",
       "      <td>0.553188</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.824301</td>\n",
       "      <td>1790-1795</td>\n",
       "      <td>True</td>\n",
       "      <td>1790</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11166 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  period  foote_novelty  foote_size  p_peak  p_trough  \\\n",
       "491047  ragged    1845      15.009504           5    0.00       1.0   \n",
       "6702     sound    1800       9.766796           4    0.00       1.0   \n",
       "742101   cloth    1830      21.480622           6    0.00       1.0   \n",
       "627159    fins    1815      14.552565           5    0.00       1.0   \n",
       "836294  ragged    1845      21.243869           6    0.00       1.0   \n",
       "...        ...     ...            ...         ...     ...       ...   \n",
       "739503   doubt    1790       0.878696           6    0.01       1.0   \n",
       "411125   serve    1800       0.592346           5    0.01       1.0   \n",
       "411126   serve    1805       0.590404           5    0.01       1.0   \n",
       "386021   doubt    1795       0.577880           5    0.01       1.0   \n",
       "386020   doubt    1790       0.553188           5    0.01       1.0   \n",
       "\n",
       "        foote_novelty_z period_str  is_signif  period_int  word_num_peaks  \n",
       "491047        18.093063  1845-1850       True        1845               3  \n",
       "6702          17.791078  1800-1805       True        1800               3  \n",
       "742101        17.663424  1830-1835       True        1830               4  \n",
       "627159        17.495118  1815-1820       True        1815               3  \n",
       "836294        17.451641  1845-1850       True        1845               3  \n",
       "...                 ...        ...        ...         ...             ...  \n",
       "739503        -0.765645  1790-1795       True        1790               2  \n",
       "411125        -0.773059  1800-1805       True        1800               2  \n",
       "411126        -0.775601  1805-1810       True        1805               2  \n",
       "386021        -0.791989  1795-1800       True        1795               2  \n",
       "386020        -0.824301  1790-1795       True        1790               2  \n",
       "\n",
       "[11166 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_signif_novelty_scores(min_foote_size=4,max_foote_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>foote_novelty</th>\n",
       "      <th>foote_size</th>\n",
       "      <th>p_peak</th>\n",
       "      <th>p_trough</th>\n",
       "      <th>foote_novelty_z</th>\n",
       "      <th>is_signif</th>\n",
       "      <th>period_int</th>\n",
       "      <th>word_num_peaks</th>\n",
       "      <th>changepoint</th>\n",
       "      <th>changepoint_avg</th>\n",
       "      <th>nov_rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ragged</th>\n",
       "      <td>1845.625000</td>\n",
       "      <td>13.318148</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.560365</td>\n",
       "      <td>True</td>\n",
       "      <td>1845.625000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>satin</th>\n",
       "      <td>1792.500000</td>\n",
       "      <td>12.993374</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.071315</td>\n",
       "      <td>True</td>\n",
       "      <td>1792.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1792.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fins</th>\n",
       "      <td>1813.333333</td>\n",
       "      <td>12.422193</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.053489</td>\n",
       "      <td>True</td>\n",
       "      <td>1813.333333</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foil</th>\n",
       "      <td>1813.333333</td>\n",
       "      <td>12.299752</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.852171</td>\n",
       "      <td>True</td>\n",
       "      <td>1813.333333</td>\n",
       "      <td>3.222222</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cloth</th>\n",
       "      <td>1831.000000</td>\n",
       "      <td>12.159483</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.991547</td>\n",
       "      <td>True</td>\n",
       "      <td>1831.000000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>1830.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>late</th>\n",
       "      <td>1867.500000</td>\n",
       "      <td>0.831305</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.247286</td>\n",
       "      <td>True</td>\n",
       "      <td>1867.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>1867.5</td>\n",
       "      <td>2664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit</th>\n",
       "      <td>1752.500000</td>\n",
       "      <td>0.773004</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>True</td>\n",
       "      <td>1752.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>1752.5</td>\n",
       "      <td>2665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extraordinary</th>\n",
       "      <td>1747.500000</td>\n",
       "      <td>0.763916</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.023954</td>\n",
       "      <td>True</td>\n",
       "      <td>1747.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>1747.5</td>\n",
       "      <td>2666.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doubt</th>\n",
       "      <td>1792.500000</td>\n",
       "      <td>0.740749</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.770226</td>\n",
       "      <td>True</td>\n",
       "      <td>1792.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1790.0</td>\n",
       "      <td>1792.5</td>\n",
       "      <td>2667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>1802.500000</td>\n",
       "      <td>0.591375</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.774330</td>\n",
       "      <td>True</td>\n",
       "      <td>1802.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>1802.5</td>\n",
       "      <td>2668.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2668 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    period  foote_novelty  foote_size    p_peak  p_trough  \\\n",
       "word                                                                        \n",
       "ragged         1845.625000      13.318148    5.125000  0.001250       1.0   \n",
       "satin          1792.500000      12.993374    6.000000  0.005000       1.0   \n",
       "fins           1813.333333      12.422193    5.222222  0.002222       1.0   \n",
       "foil           1813.333333      12.299752    5.222222  0.000000       1.0   \n",
       "cloth          1831.000000      12.159483    5.100000  0.000000       1.0   \n",
       "...                    ...            ...         ...       ...       ...   \n",
       "late           1867.500000       0.831305    4.500000  0.005000       1.0   \n",
       "hit            1752.500000       0.773004    4.000000  0.010000       1.0   \n",
       "extraordinary  1747.500000       0.763916    4.000000  0.010000       1.0   \n",
       "doubt          1792.500000       0.740749    5.500000  0.007500       1.0   \n",
       "serve          1802.500000       0.591375    5.000000  0.010000       1.0   \n",
       "\n",
       "               foote_novelty_z  is_signif   period_int  word_num_peaks  \\\n",
       "word                                                                     \n",
       "ragged               14.560365       True  1845.625000        2.750000   \n",
       "satin                10.071315       True  1792.500000        2.000000   \n",
       "fins                 13.053489       True  1813.333333        3.222222   \n",
       "foil                 12.852171       True  1813.333333        3.222222   \n",
       "cloth                12.991547       True  1831.000000        3.400000   \n",
       "...                        ...        ...          ...             ...   \n",
       "late                 -0.247286       True  1867.500000        2.000000   \n",
       "hit                  -0.005970       True  1752.500000        2.000000   \n",
       "extraordinary        -0.023954       True  1747.500000        2.000000   \n",
       "doubt                -0.770226       True  1792.500000        2.000000   \n",
       "serve                -0.774330       True  1802.500000        2.000000   \n",
       "\n",
       "               changepoint  changepoint_avg  nov_rank  \n",
       "word                                                   \n",
       "ragged              1840.0           1845.0       1.0  \n",
       "satin               1790.0           1792.5       2.0  \n",
       "fins                1805.0           1815.0       3.0  \n",
       "foil                1805.0           1815.0       4.0  \n",
       "cloth               1825.0           1830.0       5.0  \n",
       "...                    ...              ...       ...  \n",
       "late                1865.0           1867.5    2664.0  \n",
       "hit                 1750.0           1752.5    2665.0  \n",
       "extraordinary       1745.0           1747.5    2666.0  \n",
       "doubt               1790.0           1792.5    2667.0  \n",
       "serve               1800.0           1802.5    2668.0  \n",
       "\n",
       "[2668 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odfsum=get_signif_novelty_scores_summary(min_foote_size=4,max_foote_size=6)\n",
    "odfsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1607"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(odfsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nbrs('anglican')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfsign=get_signif_novelty_scores(force=True,min_peaks=2,consecutive_peaks=True,p_peak=.01)\n",
    "# dfsign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsign=get_signif_novelty_scores(force=True)\n",
    "dfsign#[dfsign.word=='culture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signw=get_signif_novelty_words()\n",
    "# 'culture' in set(signw)\n",
    "# signw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_novelty_words('ragged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfsignw=dfsign.groupby('word').mean()\n",
    "# dfsignw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfchangepoints=get_signif_novelty_scores(p_peak=.05, min_peaks=1).drop_duplicates('word',keep='first').set_index('word')\n",
    "# dfchangepoints=dfchangepoints.join(dfsignw,rsuffix='_avg_sign')\n",
    "# dfchangepoints=dfchangepoints.join(get_all_novelty_scores().groupby('word').mean(),rsuffix='_avg')\n",
    "# prefcols=['period','word_num_peaks','foote_novelty_z_avg_sign']\n",
    "# dfchangepoints = dfchangepoints[prefcols + sorted([c for c in dfchangepoints.columns if c not in set(prefcols)])]\n",
    "# dfchangepoints = dfchangepoints.sort_values('period')\n",
    "# dfchangepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topwords=dfchangepoints.sort_values(\n",
    "#     'foote_novelty_z_avg_sign',ascending=False\n",
    "# ).query('word_num_peaks>1')\n",
    "# round(topwords,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_words = get_signif_novelty_words(p_peak=0.01,min_peaks=2)\n",
    "len(sign_words), random.sample(sign_words,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign_words = get_signif_novelty_words(p_peak=0.01)\n",
    "# len(sign_words), random.sample(sign_words,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all significant words' novelties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_novelty_by_foote_size(p_peak=0.01,min_peaks=1,rolling=2, ymin=-1, nudge_x=1, labsize=6,words={}):\n",
    "    df=get_all_novelty_scores(by_foote_size=True, min_foote_size=4, max_foote_size=6)\n",
    "    if not words: words=get_signif_novelty_words(p_peak=p_peak,min_peaks=min_peaks)\n",
    "#     words={w for w in words if not 's' in w and not 'f' in w}\n",
    "    print('# words used:',len(words))\n",
    "    if words: df=df[df.word.isin(words)]\n",
    "    figdf=pd.DataFrame([\n",
    "        {\n",
    "            'foote_size':fs,\n",
    "            'period':period,\n",
    "            'num_peaks':len(grp.query(f'p_peak<{p_peak}')),\n",
    "            'avg_nov_signif':grp.query(f'p_peak<{p_peak}').foote_novelty_z.mean(),\n",
    "            'avg_nov':grp.foote_novelty_z.mean(),\n",
    "        } for ((fs,period),grp) in df.groupby([\n",
    "            'foote_size','period'\n",
    "        ])\n",
    "    ])\n",
    "    for ycol in ['avg_nov','avg_nov_signif']:\n",
    "        figdf[ycol]=figdf[ycol].rolling(rolling,min_periods=1).mean()\n",
    "    \n",
    "    fig=start_fig(\n",
    "        figdf,\n",
    "        x='period',\n",
    "        y='num_peaks',\n",
    "#         size='num_peaks',\n",
    "        color='factor(foote_size)',\n",
    "#         linetype='factor(foote_size)',\n",
    "    )\n",
    "    fig+=p9.geom_line()\n",
    "    fig+=p9.geom_point(p9.aes(shape='factor(foote_size)'))\n",
    "    \n",
    "    fig+=p9.scale_color_gray(start=.8, end=.2)\n",
    "    fig+=p9.geom_vline(xintercept=1770,linetype='dotted',alpha=0.5) \n",
    "    fig+=p9.geom_vline(xintercept=1800,linetype='dotted',alpha=0.5) \n",
    "    fig+=p9.geom_vline(xintercept=1830,linetype='dotted',alpha=0.5) \n",
    "    fig+=p9.geom_label(label='Sattelzeit begins (1770)',x=1770+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0))\n",
    "    fig+=p9.geom_label(label='Sattelzeit ends (1830)',x=1830+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0)) \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_novelty_by_foote_size(rolling=1, p_peak=.01, min_peaks=1)#, words={'culture'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_novelty_by_foote_size(rolling=1, words={'potato'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfchangepoints=get_signif_novelty_scores(p_peak=.05, min_peaks=1).drop_duplicates('word',keep='first').sort_values('period')\n",
    "# dfchangepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odfstr=pd.DataFrame([\n",
    "#     {'period':period, 'words':', '.join(grp.sort_values('foote_novelty_z',ascending=False).word)}\n",
    "#     for period,grp in sorted(dfchangepoints.groupby('period'))\n",
    "# ])\n",
    "# printm(odfstr.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_novelty_figdf(novdf):\n",
    "    figdf=novdf.sample(frac=1)\n",
    "    ywl=[\n",
    "        f'{x} years'\n",
    "        for x in figdf['foote_size']*5*2\n",
    "    ]\n",
    "    ywls=set(ywl)\n",
    "    ywll=list(reversed(sorted(list(ywls))))\n",
    "    figdf['year_window']=pd.Categorical(ywl, categories=ywll)\n",
    "    figdf['glen']=1\n",
    "    figdf['is_signif']=pd.Categorical(\n",
    "        [bool(x<0.05) for x in figdf.p_peak],\n",
    "        categories=[True,False]\n",
    "    )\n",
    "    \n",
    "    figdf = pd.concat(\n",
    "        grp.assign(foote_novelty_z=grp.foote_novelty.apply(lambda x: (x-grp.foote_novelty.mean())/grp.foote_novelty.std()))\n",
    "        for i,grp in figdf.groupby('foote_size')\n",
    "    )\n",
    "    return figdf.dropna().sort_values(['year_window','period'])\n",
    "\n",
    "\n",
    "# @interact\n",
    "def plot_novelty(\n",
    "        words=None,\n",
    "        novdf=None,\n",
    "        color='factor(year_window)',\n",
    "        group='factor(year_window)',\n",
    "        shape='factor(year_window)',\n",
    "        size='glen',\n",
    "        max_p_peak=None,\n",
    "        vnum='v9',\n",
    "        showdata=False,\n",
    "        xlab='Date of semantic model',\n",
    "        ylab='Foote Novelty (standardized)',\n",
    "        colorlab='Foote matrix width',\n",
    "        shapelab='Foote matrix width',\n",
    "        sizelab='Number of significant peaks',\n",
    "        title='Average novelty score for significant words over time',\n",
    "        rolling=2,\n",
    "        min_periods=1,\n",
    "        min_foote_size=6,\n",
    "        max_foote_size=6,\n",
    "        y='foote_novelty',\n",
    "        ymin=-.1,\n",
    "        ylim0=0,\n",
    "        ylim1=20,\n",
    "        use_ylim=False,\n",
    "        xlim0=1750,\n",
    "        xlim1=1900,\n",
    "        sizemin=.25,\n",
    "        sizemax=2,\n",
    "        labsize=6,\n",
    "        hline='',\n",
    "        nudge_label_y=1,\n",
    "        ymin_heatmap=1750,\n",
    "        combine=False,\n",
    "        use_color=False,\n",
    "        h_fig1=4.00,\n",
    "        h_fig2=4.00,\n",
    "        nudge_x=3,\n",
    "        xlab_min=1735,\n",
    "        add_median=True,\n",
    "        save=False,force=False,\n",
    "        label_words=False,\n",
    "        logy=False,\n",
    "        show_period_labels=True,\n",
    "        dist_invert_fill=False,\n",
    "        line_size=0.5,\n",
    "        label_size=7,\n",
    "        by_word=False\n",
    "        ):\n",
    "\n",
    "    wkey=''\n",
    "    if words: wkey=words.replace(' ','') if type(words)==str else '-'.join(words)\n",
    "    ofn=f'''fig.{wkey+'.' if wkey else ''}footenov.{vnum}.{xlim0}-{xlim1}--{ylim0}-{ylim1}--r{rolling}.{'cmbo.' if combine else ''}png'''\n",
    "    ofnfn=os.path.join(PATH_FIGS,ofn)\n",
    "    if save and not force and os.path.exists(ofnfn): return ofnfn\n",
    "    \n",
    "    figwords=set(words) if words else {'allwords'}\n",
    "    \n",
    "    \n",
    "    if novdf is None:\n",
    "        if words is None:\n",
    "            print('neither words nor novdf')\n",
    "            return\n",
    "        \n",
    "        novdf = get_novelty(words,min_foote_size=min_foote_size,max_foote_size=max_foote_size)\n",
    "        if not by_word: words=None\n",
    "        #print(f'Computed novelty df of shape {novdf.shape}')\n",
    "        #display(novdf.mean())\n",
    "        \n",
    "    figdf=get_plot_novelty_figdf(novdf)\n",
    "    if not len(figdf): return\n",
    "    if max_p_peak: figdf=figdf[figdf.p_peak<max_p_peak]\n",
    "    \n",
    "    \n",
    "    figdf=figdf.sort_values('period')\n",
    "    if showdata: display(figdf)\n",
    "    fig=start_fig(\n",
    "        figdf,\n",
    "        x='period',\n",
    "        y=y,\n",
    "        color=color if color else None,\n",
    "        group=group if group else None,\n",
    "        figure_size=(8,h_fig1)\n",
    "    )\n",
    "    \n",
    "    if add_median:\n",
    "        kname='Guides'\n",
    "        mediandf=pd.DataFrame([{\n",
    "            'yintercept':figdf[y].median(),\n",
    "            kname:'Median',\n",
    "        },\n",
    "        ])\n",
    "        fig+=p9.geom_hline(\n",
    "            p9.aes(yintercept='yintercept',linetype=kname),\n",
    "            data=mediandf,\n",
    "            size=.25,\n",
    "            show_legend=True\n",
    "        )\n",
    "    fig+=p9.geom_line(size=line_size)\n",
    "    pntd={}\n",
    "    if size: pntd['size']=size\n",
    "    if shape: pntd['shape']=shape\n",
    "    fig+=p9.geom_point(p9.aes(**pntd))\n",
    "    fig+=p9.labs(x=xlab,y=ylab,title=title,color=colorlab,size=sizelab,shape=shapelab)\n",
    "    if use_ylim: fig+=p9.ylim(ylim0,ylim1)\n",
    "    fig+=p9.scale_size_continuous(range=(sizemin,sizemax))\n",
    "    if not use_color: fig+=p9.scale_color_gray(direction=1)# if not use_color else p9.scale_color_distiller(type='qual')\n",
    "    if hline not in {None,''}:\n",
    "        fig+=p9.geom_hline(yintercept=hline,linetype='dotted')\n",
    "    if words and label_words:\n",
    "        labeldf=figdf[figdf.is_signif==1]\n",
    "        grps=[\n",
    "            grp.sort_values(y).iloc[-1:]\n",
    "            for i,grp in labeldf.groupby('word')\n",
    "        ]\n",
    "        if len(grps):\n",
    "            labeldf=pd.concat(grps)\n",
    "            labeldf[y]+=nudge_label_y\n",
    "            fig+=p9.geom_label(p9.aes(label='word'),color='black',\n",
    "                               size=label_size,data=labeldf,boxcolor=(0,0,0,0))\n",
    "    if show_period_labels:\n",
    "        fig+=p9.geom_vline(xintercept=1770,linetype='dotted',alpha=0.5) \n",
    "        fig+=p9.geom_vline(xintercept=1800,linetype='dotted',alpha=0.5) \n",
    "        fig+=p9.geom_vline(xintercept=1830,linetype='dotted',alpha=0.5) \n",
    "        fig+=p9.geom_label(label='Sattelzeit begins (1770)',x=1770+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0))\n",
    "        fig+=p9.geom_label(label='Sattelzeit ends (1830)',x=1830+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0)) \n",
    "    if size=='is_signif':\n",
    "        fig+=p9.scale_size_manual({True:2,False:.2})\n",
    "    else:\n",
    "        fig+=p9.scale_size_continuous(range=[.25,3])\n",
    "    fig+=p9.theme_minimal()\n",
    "    fig+=p9.theme(axis_text_x=p9.element_text(angle=90), text=p9.element_text(size=8))\n",
    "    if logy: fig+=p9.scale_y_log10(limits=[ylim0,ylim1])\n",
    "    fig+=p9.scale_x_continuous(\n",
    "        minor_breaks=list(range(xlim0//5*5,(xlim1//5*5)+5,5)),\n",
    "        limits=[xlim0,xlim1]\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    if combine:\n",
    "        yymin1=figdf.period.min()\n",
    "        yymax1=figdf.period.max()\n",
    "        figdm=plot_historical_semantic_distance_matrix(words=figwords,ymin=xlim0,ymax=xlim1)\n",
    "        ofig=combine_plots(figdm,fig,ofn=ofnfn)\n",
    "    else:\n",
    "        ofig=fig\n",
    "    \n",
    "    if save:\n",
    "        ofig.save(ofnfn)\n",
    "        if PATH_FIGS2: fig.save(os.path.join(PATH_FIGS2,ofn))\n",
    "        return ofnfn\n",
    "\n",
    "    return ofig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_novelty('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_novelty_words(words,**kwargs):\n",
    "    inpd=dict(\n",
    "        y='foote_novelty_z',\n",
    "        words=to_words(words),\n",
    "        color='word',\n",
    "        group='word',\n",
    "        shape='word',\n",
    "        colorlab='Word',\n",
    "        shapelab='Word',\n",
    "        sizelab='Statistically significant',\n",
    "        title='Novelty scores for key words',\n",
    "        ylab='Foote Novelty score',\n",
    "        size='is_signif',\n",
    "        vnum='v19',\n",
    "        use_ylim=False,\n",
    "        add_median=True,\n",
    "        max_p_peak=0.0,\n",
    "        min_foote_size=6,\n",
    "        max_foote_size=6,\n",
    "        showdata=False,\n",
    "        nudge_x=2,\n",
    "        logy=False,\n",
    "        ylim0=0,\n",
    "        ylim1=10,\n",
    "        xlim0=1745,\n",
    "        xlim1=1870,\n",
    "        rolling=2,\n",
    "        ymin=-1.5,\n",
    "        label_words=True,\n",
    "        show_period_labels=True,\n",
    "        nudge_label_y=0.25,\n",
    "        save=False,\n",
    "        by_word=True\n",
    "    )\n",
    "    return plot_novelty(**{**inpd, **kwargs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_novelty_words('station,stations,culture,slave,demand,value,honour,revolution',save=False)\n",
    "# plot_novelty_words('station')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_historical_semantic_distance_matrix('virtue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_novelty_words('value',min_foote_size=5,max_foote_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_novelty_words('monday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
