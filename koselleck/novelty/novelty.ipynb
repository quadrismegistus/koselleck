{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipynb.fs.full.koselleck'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bb310eca71dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkoselleck\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipynb.fs.full.koselleck'"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.koselleck import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nov_word(word,progress=False,**kwargs):\n",
    "    odf=test_novelty(get_historical_semantic_distance_matrix(\n",
    "            word,\n",
    "            interpolate=True,\n",
    "            normalize=True,\n",
    "            progress=progress\n",
    "        ),\n",
    "        **kwargs\n",
    "    )\n",
    "    if odf is not None and len(odf):\n",
    "        odf=odf.query('foote_novelty!=0').assign(word=word)\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_novelty' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cb7f0c5453f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnov_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'virtue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-805c1e780f8f>\u001b[0m in \u001b[0;36mnov_word\u001b[0;34m(word, progress, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnov_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     odf=test_novelty(get_historical_semantic_distance_matrix(\n\u001b[0m\u001b[1;32m      3\u001b[0m             \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0minterpolate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_novelty' is not defined"
     ]
    }
   ],
   "source": [
    "nov_word('virtue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_novelty(words=None,interpolate=True,by_word=True,progress=True, lim=None, num_proc=1, force=False,use_all_word_cache=False, **y):\n",
    "    if words is None: words=get_valid_words()\n",
    "    words=tokenize_fast(words) if type(words)==str else words\n",
    "    veclib=get_veclib()\n",
    "    if use_all_word_cache and os.path.exists(FN_NOV_ALL_BYWORD):\n",
    "        odf=get_all_novelty_scores(by_foote_size=True)\n",
    "        odf=odf[odf.word.isin(words)]\n",
    "        if not by_word: odf=odf.groupby(['foote_size','period']).mean().reset_index()\n",
    "    else:\n",
    "        if by_word:\n",
    "            o=[]\n",
    "            words_todo=words\n",
    "            words_done=pd.DataFrame()\n",
    "            if not force:\n",
    "                words_done = pd.DataFrame([\n",
    "                    dx\n",
    "                    for word in words\n",
    "                    for dx in veclib.get(f'nov({word})',[])\n",
    "                    if type(dx)==dict\n",
    "                ])\n",
    "                display(words_done)\n",
    "                if len(words_done):\n",
    "                    words_todo = list(set(words) - set(words_done.word))\n",
    "            \n",
    "            for dfg in pmap_iter(\n",
    "                do_get_novelty,\n",
    "                words_todo[:lim],\n",
    "                progress=progress,\n",
    "                desc='Calculating novelty for words',\n",
    "                num_proc=num_proc,\n",
    "                kwargs=dict(progress=False)\n",
    "            ):\n",
    "                if dfg is None or not len(dfg): continue                \n",
    "                word=dfg.iloc[0].word\n",
    "#                 display(dfg)\n",
    "#                 display(dfg.to_dict('records'))\n",
    "                veclib[f'nov({word})']=dfg.to_dict('records')\n",
    "                o+=[dfg]\n",
    "            odf=words_done.append(pd.concat(o) if len(o) else pd.DataFrame())\n",
    "        else:\n",
    "            distdf=get_historical_semantic_distance_matrix(words,interpolate=interpolate)\n",
    "            odf=test_novelty(distdf,**y)\n",
    "        odf['period']=[int(x[:4]) for x in odf.period]\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do_get_novelty('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>foote_novelty</th>\n",
       "      <th>foote_size</th>\n",
       "      <th>p_peak</th>\n",
       "      <th>p_trough</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1730-1735</td>\n",
       "      <td>3.191489</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1735-1740</td>\n",
       "      <td>-107.402482</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1740-1745</td>\n",
       "      <td>-78.383570</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1745-1750</td>\n",
       "      <td>5.718085</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1750-1755</td>\n",
       "      <td>-24.660165</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>consumer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>1905-1910</td>\n",
       "      <td>635.106383</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>reformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>1910-1915</td>\n",
       "      <td>1126.462766</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>reformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>1915-1920</td>\n",
       "      <td>1469.015957</td>\n",
       "      <td>6</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.00</td>\n",
       "      <td>reformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>1920-1925</td>\n",
       "      <td>1663.918440</td>\n",
       "      <td>6</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.00</td>\n",
       "      <td>reformation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1925-1930</td>\n",
       "      <td>1817.420213</td>\n",
       "      <td>6</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>reformation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2996 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         period  foote_novelty  foote_size  p_peak  p_trough         word\n",
       "0     1730-1735       3.191489           2    1.00      0.49     consumer\n",
       "1     1735-1740    -107.402482           2    1.00      0.99     consumer\n",
       "2     1740-1745     -78.383570           2    1.00      0.99     consumer\n",
       "3     1745-1750       5.718085           2    1.00      0.26     consumer\n",
       "4     1750-1755     -24.660165           2    1.00      0.99     consumer\n",
       "...         ...            ...         ...     ...       ...          ...\n",
       "2991  1905-1910     635.106383           6    1.00      1.00  reformation\n",
       "2992  1910-1915    1126.462766           6    0.99      1.00  reformation\n",
       "2993  1915-1920    1469.015957           6    0.42      1.00  reformation\n",
       "2994  1920-1925    1663.918440           6    0.11      1.00  reformation\n",
       "2995  1925-1930    1817.420213           6    0.04      1.00  reformation\n",
       "\n",
       "[2996 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating novelty for words [x4]:   5%|▌         | 11/203 [00:05<02:15,  1.42it/s]Reading from /home/ryan/github/koselleck/data/data.all_models_halfdec.pkl\n"
     ]
    }
   ],
   "source": [
    "all_nov=get_novelty(get_keywords_l(),num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nov_scores = get_novelty(\n",
    "    get_valid_words(),\n",
    "    progress=True,\n",
    "    num_proc=2\n",
    ")\n",
    "all_nov_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_novelty_scores(ifnfn=FN_NOV_ALL_BYWORD,\n",
    "                           by_foote_size=False, min_foote_size=6, max_foote_size=6):\n",
    "    global DFALLNOV\n",
    "    if DFALLNOV is not None:\n",
    "        odf=DFALLNOV\n",
    "    elif not os.path.exists(ifnfn):\n",
    "        print(f'Generating novelty scores, saving to {ifnfn}')\n",
    "        DFALLNOV = odf = nov_all_byword = get_novelty(by_word=True,progress=True,num_proc=1)\n",
    "        nov_all_byword.to_pickle(FN_NOV_ALL_BYWORD)\n",
    "    else:\n",
    "        print(f'Loading novelty scores from {ifnfn}')\n",
    "        with open(ifnfn,'rb') as f: odf=pickle.load(f)\n",
    "        DFALLNOV=odf\n",
    "        \n",
    "    odf = odf.query(f'foote_novelty!=0 & {min_foote_size}<=foote_size<={max_foote_size}')\n",
    "    odf = pd.concat(\n",
    "        grp.assign(\n",
    "            foote_novelty_z=(grp.foote_novelty - grp.foote_novelty.mean()) / grp.foote_novelty.std()\n",
    "        )\n",
    "        for i,grp in odf.groupby('foote_size')\n",
    "    )\n",
    "    if not by_foote_size:\n",
    "        odf=odf.groupby(['word','period']).mean().drop('foote_size',1).reset_index()\n",
    "    else:\n",
    "        odf['foote_size']=odf.foote_size.apply(int)\n",
    "        \n",
    "    #odf=odf.query('period<1900')\n",
    "    return odf\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_novelty('virtue,value',by_word=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_novelty('station', by_word=False).query('foote_novelty!=0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nov_all_mean=get_novelty(by_word=False)\n",
    "# nov_all_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_novelty_scores(by_foote_size=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signif_novelty_scores(p_peak=0.05,min_peaks=1):\n",
    "    odf=get_all_novelty_scores().query(f'p_peak<{p_peak}')\n",
    "    odf=pd.concat(\n",
    "        grp.assign(\n",
    "            word_num_peaks=len(grp[grp.p_peak<p_peak])\n",
    "        ) for i,grp in odf.groupby('word')\n",
    "    )\n",
    "    if min_peaks: odf=odf[odf.word_num_peaks>=min_peaks]\n",
    "    return odf.sort_values('foote_novelty_z',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_signif_novelty_scores(\n",
    "    p_peak=0.05\n",
    ").groupby('word').mean().sort_values('foote_novelty_z',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signif_novelty_words(p_peak=0.05,min_peaks=1):\n",
    "    df=get_all_novelty_scores()\n",
    "    dfsign=get_signif_novelty_scores(p_peak=p_peak,min_peaks=min_peaks)\n",
    "    signwset=set(dfsign.word)\n",
    "    o=[\n",
    "        w for w in \n",
    "        df.groupby('word').mean().sort_values('foote_novelty',ascending=False).index\n",
    "        if w in signwset\n",
    "    ]\n",
    "    print('# all words',len(set(df.word)))\n",
    "    print('# signif words',len(set(dfsign.word)))\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_words = get_signif_novelty_words(p_peak=0.05)\n",
    "print(len(sign_words), sign_words[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting all significant words' novelties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_novelty_by_foote_size(p_peak=0.01,min_peaks=1,rolling=2, ymin=-1, nudge_x=1, labsize=6,words={}):\n",
    "    df=get_all_novelty_scores(by_foote_size=True, min_foote_size=4, max_foote_size=6)\n",
    "    if not words: words=get_signif_novelty_words(p_peak=p_peak,min_peaks=min_peaks)\n",
    "#     words={w for w in words if not 's' in w and not 'f' in w}\n",
    "    print('# words used:',len(words))\n",
    "    if words: df=df[df.word.isin(words)]\n",
    "    figdf=pd.DataFrame([\n",
    "        {\n",
    "            'foote_size':fs,\n",
    "            'period':period,\n",
    "            'num_peaks':len(grp.query(f'p_peak<{p_peak}')),\n",
    "            'avg_nov_signif':grp.query(f'p_peak<{p_peak}').foote_novelty_z.mean(),\n",
    "            'avg_nov':grp.foote_novelty_z.mean(),\n",
    "        } for ((fs,period),grp) in df.groupby([\n",
    "            'foote_size','period'\n",
    "        ])\n",
    "    ])\n",
    "    for ycol in ['avg_nov','avg_nov_signif']:\n",
    "        figdf[ycol]=figdf[ycol].rolling(rolling,min_periods=1).mean()\n",
    "    \n",
    "    fig=start_fig(\n",
    "        figdf,\n",
    "        x='period',\n",
    "        y='num_peaks',\n",
    "#         size='num_peaks',\n",
    "        color='factor(foote_size)',\n",
    "#         linetype='factor(foote_size)',\n",
    "    )\n",
    "    fig+=p9.geom_line()\n",
    "    fig+=p9.geom_point(p9.aes(shape='factor(foote_size)'))\n",
    "    \n",
    "    fig+=p9.scale_color_gray(start=.8, end=.2)\n",
    "    fig+=p9.geom_vline(xintercept=1770,linetype='dotted',alpha=0.5) \n",
    "    fig+=p9.geom_vline(xintercept=1800,linetype='dotted',alpha=0.5) \n",
    "    fig+=p9.geom_vline(xintercept=1830,linetype='dotted',alpha=0.5) \n",
    "    fig+=p9.geom_label(label='Sattelzeit begins (1770)',x=1770+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0))\n",
    "    fig+=p9.geom_label(label='Sattelzeit ends (1830)',x=1830+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0)) \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_novelty_by_foote_size(rolling=1, p_peak=.01, min_peaks=1)#, words={'culture'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_novelty_by_foote_size(rolling=1, words={'potato'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfchangepoints=get_signif_novelty_scores(p_peak=.05, min_peaks=1).drop_duplicates('word',keep='first').sort_values('period')\n",
    "dfchangepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odfstr=pd.DataFrame([\n",
    "    {'period':period, 'words':', '.join(grp.sort_values('foote_novelty_z',ascending=False).word)}\n",
    "    for period,grp in sorted(dfchangepoints.groupby('period'))\n",
    "])\n",
    "printm(odfstr.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_novelty_figdf(novdf):\n",
    "    figdf=novdf.sample(frac=1)\n",
    "    ywl=[\n",
    "        f'{x} years'\n",
    "        for x in figdf['foote_size']*5*2\n",
    "    ]\n",
    "    ywls=set(ywl)\n",
    "    ywll=list(reversed(sorted(list(ywls))))\n",
    "    figdf['year_window']=pd.Categorical(ywl, categories=ywll)\n",
    "    figdf['glen']=1\n",
    "    figdf['is_signif']=pd.Categorical(\n",
    "        [bool(x<0.05) for x in figdf.p_peak],\n",
    "        categories=[True,False]\n",
    "    )\n",
    "    \n",
    "    figdf = pd.concat(\n",
    "        grp.assign(foote_novelty_z=grp.foote_novelty.apply(lambda x: (x-grp.foote_novelty.mean())/grp.foote_novelty.std()))\n",
    "        for i,grp in figdf.groupby('foote_size')\n",
    "    )\n",
    "    return figdf.dropna().sort_values(['year_window','period'])\n",
    "\n",
    "\n",
    "# @interact\n",
    "def plot_novelty(\n",
    "        words=None,\n",
    "        novdf=None,\n",
    "        color='factor(year_window)',\n",
    "        group='factor(year_window)',\n",
    "        shape='factor(year_window)',\n",
    "        size='glen',\n",
    "        max_p_peak=None,\n",
    "        vnum='v9',\n",
    "        showdata=False,\n",
    "        xlab='Date of semantic model',\n",
    "        ylab='Foote Novelty (standardized)',\n",
    "        colorlab='Foote matrix width',\n",
    "        shapelab='Foote matrix width',\n",
    "        sizelab='Number of significant peaks',\n",
    "        title='Average novelty score for significant words over time',\n",
    "        rolling=2,\n",
    "        min_periods=1,\n",
    "        min_foote_size=6,\n",
    "        max_foote_size=6,\n",
    "        y='foote_novelty',\n",
    "        ymin=-.1,\n",
    "        ylim0=0,\n",
    "        ylim1=20,\n",
    "        use_ylim=False,\n",
    "        xlim0=1750,\n",
    "        xlim1=1900,\n",
    "        sizemin=.25,\n",
    "        sizemax=2,\n",
    "        labsize=6,\n",
    "        hline='',\n",
    "        nudge_label_y=1,\n",
    "        ymin_heatmap=1750,\n",
    "        combine=False,\n",
    "        use_color=False,\n",
    "        h_fig1=4.00,\n",
    "        h_fig2=4.00,\n",
    "        nudge_x=3,\n",
    "        xlab_min=1735,\n",
    "        add_median=True,\n",
    "        save=False,\n",
    "        label_words=False,\n",
    "        logy=False,\n",
    "        show_period_labels=True,\n",
    "        dist_invert_fill=False,\n",
    "        line_size=0.5,\n",
    "        label_size=7,\n",
    "        by_word=False\n",
    "        ):\n",
    "\n",
    "    figwords=set(words) if words else {'allwords'}\n",
    "    if novdf is None:\n",
    "        if words is None:\n",
    "            print('neither words nor novdf')\n",
    "            return\n",
    "        \n",
    "        novdf = get_novelty(words,by_word=by_word)\n",
    "        if not by_word: words=None\n",
    "        print(f'Computed novelty df of shape {novdf.shape}')\n",
    "#         display(novdf)\n",
    "        \n",
    "#     figdf=get_plot_novelty_figdf(novdf.query(f'{min_foote_size}<=foote_size<={max_foote_size}'))\n",
    "    figdf=get_plot_novelty_figdf(novdf)\n",
    "    if not len(figdf): return\n",
    "    if max_p_peak: figdf=figdf[figdf.p_peak<max_p_peak]\n",
    "    \n",
    "    \n",
    "    figdf=figdf.sort_values('period')\n",
    "    if showdata: display(figdf)\n",
    "    fig=start_fig(\n",
    "        figdf,\n",
    "        x='period',\n",
    "        y=y,\n",
    "        color=color if color else None,\n",
    "        group=group if group else None,\n",
    "        figure_size=(8,h_fig1)\n",
    "    )\n",
    "    \n",
    "    if add_median:\n",
    "        kname='Guides'\n",
    "        mediandf=pd.DataFrame([{\n",
    "            'yintercept':figdf[y].median(),\n",
    "            kname:'Median',\n",
    "        },\n",
    "        ])\n",
    "        fig+=p9.geom_hline(\n",
    "            p9.aes(yintercept='yintercept',linetype=kname),\n",
    "            data=mediandf,\n",
    "            size=.25,\n",
    "            show_legend=True\n",
    "        )\n",
    "    fig+=p9.geom_line(size=line_size)\n",
    "    pntd={}\n",
    "    if size: pntd['size']=size\n",
    "    if shape: pntd['shape']=shape\n",
    "    fig+=p9.geom_point(p9.aes(**pntd))\n",
    "    fig+=p9.labs(x=xlab,y=ylab,title=title,color=colorlab,size=sizelab,shape=shapelab)\n",
    "    if use_ylim: fig+=p9.ylim(ylim0,ylim1)\n",
    "    fig+=p9.scale_size_continuous(range=(sizemin,sizemax))\n",
    "    if not use_color: fig+=p9.scale_color_gray(direction=1)# if not use_color else p9.scale_color_distiller(type='qual')\n",
    "    if hline not in {None,''}:\n",
    "        fig+=p9.geom_hline(yintercept=hline,linetype='dotted')\n",
    "    if words and label_words:\n",
    "        labeldf=figdf[figdf.is_signif==1]\n",
    "        grps=[\n",
    "            grp.sort_values(y).iloc[-1:]\n",
    "            for i,grp in labeldf.groupby('word')\n",
    "        ]\n",
    "        if len(grps):\n",
    "            labeldf=pd.concat(grps)\n",
    "            labeldf[y]+=nudge_label_y\n",
    "            fig+=p9.geom_label(p9.aes(label='word'),color='black',\n",
    "                               size=label_size,data=labeldf,boxcolor=(0,0,0,0))\n",
    "    if show_period_labels:\n",
    "        fig+=p9.geom_vline(xintercept=1770,linetype='dotted',alpha=0.5) \n",
    "        fig+=p9.geom_vline(xintercept=1800,linetype='dotted',alpha=0.5) \n",
    "        fig+=p9.geom_vline(xintercept=1830,linetype='dotted',alpha=0.5) \n",
    "        fig+=p9.geom_label(label='Sattelzeit begins (1770)',x=1770+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0))\n",
    "        fig+=p9.geom_label(label='Sattelzeit ends (1830)',x=1830+nudge_x,y=ymin,angle=90,size=labsize,color='black',va='bottom',boxcolor=(0,0,0,0)) \n",
    "    if size=='is_signif':\n",
    "        fig+=p9.scale_size_manual({True:2,False:.2})\n",
    "    else:\n",
    "        fig+=p9.scale_size_continuous(range=[.25,3])\n",
    "    fig+=p9.theme_minimal()\n",
    "    fig+=p9.theme(axis_text_x=p9.element_text(angle=90), text=p9.element_text(size=8))\n",
    "    if logy: fig+=p9.scale_y_log10(limits=[ylim0,ylim1])\n",
    "    fig+=p9.scale_x_continuous(\n",
    "        minor_breaks=list(range(xlim0//5*5,(xlim1//5*5)+5,5)),\n",
    "        limits=[xlim0,xlim1]\n",
    "    )\n",
    "    wkey=''\n",
    "    if words: wkey=words.replace(' ','') if type(words)==str else '-'.join(words)\n",
    "    ofn=f'''fig.footenov.{vnum}.{wkey+'.' if wkey else ''}{'cmbo.' if combine else ''}png'''\n",
    "    ofnfn=os.path.join(PATH_FIGS,ofn)\n",
    "\n",
    "    if combine:\n",
    "        yymin1=figdf.period.min()\n",
    "        yymax1=figdf.period.max()\n",
    "        figdm=plot_historical_semantic_distance_matrix(words=figwords,ymin=xlim0,ymax=xlim1)\n",
    "        ofig=combine_plots(figdm,fig,ofn=ofnfn)\n",
    "    else:\n",
    "        ofig=fig\n",
    "        if save: ofig.save(ofnfn)\n",
    "    display(ofig)\n",
    "    if save: upfig(ofnfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_novelty_words(words,**kwargs):\n",
    "    words=[w.strip() for w in words.split(',')] if type(words)==str else list(words)\n",
    "    inpd=dict(\n",
    "        y='foote_novelty_z',\n",
    "        words=words,\n",
    "        color='word',\n",
    "        group='word',\n",
    "        shape='word',\n",
    "        colorlab='Word',\n",
    "        shapelab='Word',\n",
    "        sizelab='Statistically significant',\n",
    "        title='Novelty scores for key words',\n",
    "        ylab='Foote Novelty score',\n",
    "        size='is_signif',\n",
    "        vnum='v19',\n",
    "        use_ylim=False,\n",
    "        add_median=True,\n",
    "        max_p_peak=0.0,\n",
    "        min_foote_size=5,\n",
    "        max_foote_size=5,\n",
    "        showdata=False,\n",
    "        nudge_x=2,\n",
    "        logy=False,\n",
    "        ylim0=0,\n",
    "        ylim1=10,\n",
    "        xlim0=1740,\n",
    "        xlim1=1940,\n",
    "        rolling=2,\n",
    "        ymin=.1,\n",
    "        label_words=True,\n",
    "        show_period_labels=True,\n",
    "        nudge_label_y=0.25,\n",
    "        save=True,\n",
    "        by_word=True\n",
    "    )\n",
    "    return plot_novelty(**{**inpd, **kwargs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_novelty_words('station,value,commerce,growth,culture,slave,slavery,god,time,december')\n",
    "plot_novelty_words('station,value,slave,demand,interest,circulation,improvement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
