{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56fc5b9-e20d-4978-bac9-de4c5353d231",
   "metadata": {},
   "source": [
    "# Simplified functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56e8fd9-7912-43f1-b49c-ba3e135b50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.koselleck import *\n",
    "w='culture'\n",
    "YMIN_WDIST=YMIN_NBR\n",
    "YMAX_WDIST=YMAX_NBR\n",
    "YBIN_WDIST=YBIN_NBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42324a1d-981c-423c-9bd5-83488beaed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_corpora_periods(\n",
    "        word_or_words, period_or_periods=None, corpus_or_corpora=DEFAULT_CORPUS,\n",
    "        ybin=YBIN_WDIST, ymin=YMIN_WDIST, ymax=YMAX_WDIST):\n",
    "    words=to_words(word_or_words)\n",
    "    corpora=to_words(corpus_or_corpora)\n",
    "    periods=to_words(period_or_periods) if period_or_periods else get_periods_bystep(\n",
    "        ymin=ymin,ymax=ymax,ybin=ybin\n",
    "    )\n",
    "    return words,corpora,periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a603df3f-b7a8-4aab-917d-32f1dc3d74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wdist(word_or_words, period_or_periods=None, corpus_or_corpora=DEFAULT_CORPUS,\n",
    "          ybin=YBIN_WDIST, ymin=YMIN_WDIST, ymax=YMAX_WDIST, **attrs):\n",
    "    words,corpora,periods = get_words_corpora_periods(\n",
    "        word_or_words,period_or_periods,corpus_or_corpora,\n",
    "        ybin=ybin,ymin=ymin,ymax=ymax\n",
    "    )\n",
    "    queries = [f'{w}/{c}/{p}' for w in words for c in corpora for p in periods]\n",
    "    with get_db('wdists',mode='r') as db:\n",
    "        d=dict(\n",
    "            (\n",
    "                qstr.replace('/','_'),\n",
    "                db[qstr]\n",
    "            )\n",
    "            for qstr in queries\n",
    "            if qstr in db and len(db[qstr])\n",
    "        )\n",
    "        odf=pd.DataFrame(dict((k,v) for k,v in d.items() if len(v)))\n",
    "        odf['_avg_']=odf.mean(axis=1)\n",
    "        return odf.sort_values('_avg_').drop('_avg_',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bf538ec-efa1-4615-92d0-471be64ac805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wdist(random.choice(get_valid_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23087523-d88d-456f-a21a-bf3e518356de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wdist('value',ybin=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e656022-ee5a-4856-b24d-ace3173f7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_NBR=100\n",
    "\n",
    "def nbr(word_or_words,ntop=K_NBR,**wdist_opts):\n",
    "    dfdists = wdist(word_or_words,**wdist_opts)\n",
    "    l=[]\n",
    "    for col in dfdists.columns:\n",
    "        s=dfdists[col].sort_values().iloc[:ntop]\n",
    "        srank=s.rank(ascending=True)\n",
    "        for sword,sval,srankval in zip(s.index,s,srank):\n",
    "            word,corpus,period=col.split('_')\n",
    "            dx=dict(\n",
    "                word=word,\n",
    "                corpus=corpus,\n",
    "                period=period,\n",
    "                neighbor=sword,\n",
    "                dist=sval,\n",
    "                rank=int(srankval)\n",
    "            )\n",
    "            l.append(dx)\n",
    "    return pd.DataFrame(l).set_index(['word','corpus','period','neighbor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1b4a14e-e78b-4a13-b5f0-654c483d96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbr(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20874b7d-7ad2-4091-9ae6-68aab97f06db",
   "metadata": {},
   "source": [
    "## LNM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6cad6e-816d-4ebd-87e8-66fc1d9a28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ldist(word_or_words, k=K, incl_words=False, force=False,progress=True,num_proc=1,\n",
    "#           ybin=YBIN_DISTMAT, ymin=YMIN_DISTMAT, ymax=YMAX_DISTMAT, **wdist_opts):\n",
    "#     dfdist=wdist(word_or_words=word_or_words, ybin=ybin, ymin=ymin, ymax=ymax, **wdist_opts)\n",
    "#     l=[]\n",
    "#     qcols=[(col1,col2,f\"{col1}/{col2}/k={k}/incl_words={incl_words}\") for col1 in dfdist.columns for col2 in dfdist.columns if col1<col2]\n",
    "\n",
    "#     dbdone,dbqueue={},{}\n",
    "#     if force:\n",
    "#         ql=qcols\n",
    "#     else:\n",
    "#         with get_db('ldist',mode='r') as db:\n",
    "#             for q in qcols:\n",
    "#                 if q[-1] in db:\n",
    "#                     dbdone[q[-1]]=db[q[-1]]\n",
    "#             ql=[q for q in qcols if not q[-1] in dbdone]\n",
    "    \n",
    "#     if len(ql):\n",
    "#         objs = [\n",
    "#             (dfdist[col1],dfdist[col2],k,incl_words)\n",
    "#             for col1,col2,qstr in ql\n",
    "#         ]\n",
    "#         iterr = pmap_iter(do_ldist, objs, num_proc=num_proc, progress=progress)\n",
    "#         for (col1,col2,qstr),odx in zip(ql,iterr):\n",
    "#             odx['word1'],odx['corpus1'],odx['period1']=col1.split('_')\n",
    "#             odx['word2'],odx['corpus2'],odx['period2']=col2.split('_')\n",
    "#             dbqueue[qstr]=odx\n",
    "        \n",
    "#         with get_db('ldist',mode='c') as db:\n",
    "#             for qstr,odx in dbqueue.items():\n",
    "#                 db[qstr]=odx\n",
    "#             db.commit()\n",
    "        \n",
    "#     odf=pd.DataFrame(list(dbdone.values()) + list(dbqueue.values()))\n",
    "#     if len(odf): odf=odf.set_index(['word1','word2','corpus1','corpus2','period1','period2'])\n",
    "#     return odf\n",
    "\n",
    "def ldist_qstr(col1,col2,k,incl_words):\n",
    "    return f\"{col1}/{col2}/k={k}/incl_words={incl_words}\"\n",
    "\n",
    "def ldist_word_qstr(word,ymin=YMIN_DISTMAT,ymax=YMAX_DISTMAT,ybin=YBIN_DISTMAT,k=K,\n",
    "                    corpus=DEFAULT_CORPUS):\n",
    "    return f'{word}/{corpus}/{ymin}-{ymax}_{ybin}'\n",
    "\n",
    "def ldist(word_or_words, **ldist_iter_opts):\n",
    "    l=[res for res in ldist_iter(word_or_words, **ldist_iter_opts)]\n",
    "    return pd.concat(l) if len(l) else pd.DataFrame()\n",
    "\n",
    "def ldist_iter(word_or_words, force=False, num_proc=1,\n",
    "               ymin=YMIN_DISTMAT,ymax=YMAX_DISTMAT,ybin=YBIN_DISTMAT,k=K,\n",
    "               corpus=DEFAULT_CORPUS,commit_byword=False,\n",
    "               **ldist_word_opts):\n",
    "    objs=[\n",
    "        dict(word=w, force=force, progress=False, num_proc=1 if commit_byword else num_proc,\n",
    "             commit=not commit_byword, return_dict=False, qstr=ldist_word_qstr(\n",
    "                w,ymin=ymin,ymax=ymax,ybin=ybin,k=k,corpus=corpus\n",
    "             ), **ldist_word_opts)\n",
    "        for w in to_words(word_or_words)\n",
    "    ]\n",
    "    \n",
    "    iterr=pmap_iter(\n",
    "        ldist_word_,\n",
    "        objs,\n",
    "        num_proc=1 if not commit_byword else num_proc\n",
    "    )\n",
    "        #for i,dbd in enumerate(iterr):\n",
    "        #    for qstr,odx in dbd.items(): db[qstr]=odx\n",
    "        #    if i and not i%100: db.commit()\n",
    "        #    odf=pd.DataFrame(dbd.values())\n",
    "    \n",
    "    if commit_byword:\n",
    "        with get_db('ldist',mode='c') as db:\n",
    "            for i,(obj,odf) in enumerate(zip(objs,iterr)):\n",
    "                if odf is not None and len(odf):\n",
    "                    db[obj['qstr']]=odf\n",
    "                    yield odf\n",
    "                if i and not i%10: db.commit()\n",
    "            db.commit()\n",
    "    else:\n",
    "        yield from iterr\n",
    "    \n",
    "def ldist_word_(objd): return ldist_word(**objd)\n",
    "def ldist_word(word,\n",
    "               k=K,\n",
    "               incl_words=False,\n",
    "               force=False,\n",
    "               progress=True,\n",
    "               num_proc=1,\n",
    "               ybin=YBIN_DISTMAT,\n",
    "               ymin=YMIN_DISTMAT,\n",
    "               ymax=YMAX_DISTMAT,\n",
    "               return_dict=False,\n",
    "               commit=True,\n",
    "               **wdist_opts):\n",
    "    dfdist=wdist(word, ybin=ybin, ymin=ymin, ymax=ymax, **wdist_opts)\n",
    "    l=[]\n",
    "    qcols=[\n",
    "        (col1,col2,ldist_qstr(col1,col2,k,incl_words))\n",
    "        for col1 in dfdist.columns for col2 in dfdist.columns if col1<col2\n",
    "    ]\n",
    "\n",
    "    dbdone,dbqueue={},{}\n",
    "    if force or not commit:\n",
    "        ql=qcols\n",
    "    else:\n",
    "        with get_db('ldist',mode='r') as db:\n",
    "            for q in qcols:\n",
    "                if q[-1] in db:\n",
    "                    dbdone[q[-1]]=db[q[-1]]\n",
    "            ql=[q for q in qcols if not q[-1] in dbdone]\n",
    "    \n",
    "    if len(ql):\n",
    "        objs = [\n",
    "            (dfdist[col1],dfdist[col2],k,incl_words)\n",
    "            for col1,col2,qstr in ql\n",
    "        ]\n",
    "        iterr = pmap_iter(do_ldist, objs, num_proc=num_proc, progress=progress)\n",
    "        for (col1,col2,qstr),odx in zip(ql,iterr):\n",
    "            odx['word1'],odx['corpus1'],odx['period1']=col1.split('_')\n",
    "            odx['word2'],odx['corpus2'],odx['period2']=col2.split('_')\n",
    "            dbqueue[qstr]=odx\n",
    "        \n",
    "        if commit:\n",
    "            with get_db('ldist',mode='c') as db:\n",
    "                for qstr,odx in dbqueue.items():\n",
    "                    db[qstr]=odx\n",
    "                db.commit()\n",
    "    \n",
    "    dbd={**dbdone, **dbqueue}\n",
    "    if return_dict: return dbd\n",
    "    odf=pd.DataFrame(dbd.values())\n",
    "    if len(odf): odf=odf.set_index(['word1','word2','corpus1','corpus2','period1','period2'])\n",
    "    return odf\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def do_ldist(obj):\n",
    "    s1,s2,k,incl_words=obj\n",
    "    s1,s2=s1.dropna(),s2.dropna()\n",
    "    valid_words_now=set(s1.index) & set(s2.index)\n",
    "    s1=s1.loc[valid_words_now].sort_values()\n",
    "    s2=s2.loc[valid_words_now].sort_values()\n",
    "\n",
    "    # get top words for each\n",
    "    nb1=s1.iloc[:k].index\n",
    "    nb2=s2.iloc[:k].index\n",
    "\n",
    "    # get meta neighborhoods\n",
    "    mnb=list(set(nb1)|set(nb2))\n",
    "    nb1s=s1.loc[mnb]\n",
    "    nb2s=s2.loc[mnb]\n",
    "\n",
    "    # try to get distance\n",
    "    try:\n",
    "        #print(f'Computing: {col1} vs {col2}')\n",
    "        distdists = 1-fastdist.cosine(nb1s.values.astype(float), nb2s.values.astype(float))\n",
    "    except ZeroDivisionError as e:\n",
    "        distdists=np.nan\n",
    "\n",
    "    # return dict as df\n",
    "    odx={\n",
    "        'dist':distdists,\n",
    "        'mneighb_size':len(mnb),\n",
    "        'neighb1_size':len(nb1),\n",
    "        'neighb2_size':len(nb2),\n",
    "        'neighb1':', '.join(nb1) if incl_words else '',\n",
    "        'neighb2':', '.join(nb2) if incl_words else '',\n",
    "    }\n",
    "    return odx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e423075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wl=get_valid_words()\n",
    "# for df in ldist_iter(wl, num_proc=4, commit_byword=False): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6730c9",
   "metadata": {},
   "source": [
    "## Distmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24436b38-25bc-403d-8781-77dbb84d0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distmat(word, **ldist_opts):\n",
    "    dfldist=ldist_word(word, **ldist_opts)\n",
    "    idf=dfldist.reset_index()\n",
    "    idf=idf.append(idf.assign(period1=idf.period2, period2=idf.period1))\n",
    "    dfdistmat=idf.pivot('period1','period2','dist')\n",
    "    return dfdistmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87eee88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pmap_iter??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8e5453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_distmats_(objd):\n",
    "    try:\n",
    "        return distmat(**objd)\n",
    "    except Exception as e:\n",
    "        #print('!!',e)\n",
    "        return pd.DataFrame()\n",
    "def gen_distmats(words=None,\n",
    "                 ymin=YMIN_DISTMAT, ymax=YMAX_DISTMAT, ybin=YBIN_DISTMAT, k=K,\n",
    "                 num_proc=1,force=False,shuffle=True,lim=None,\n",
    "                 **ldist_opts):\n",
    "    if not words: words=get_valid_words()\n",
    "    words=to_words(words)\n",
    "    if shuffle: random.shuffle(words)\n",
    "    def to_qstr(w): return f'{w}/{ymin}-{ymax}_{ybin}/k={k}'\n",
    "    with get_db('distmat',mode='c') as db:\n",
    "        objs=[\n",
    "            dict(word=word, ymin=ymin, ymax=ymax, ybin=ybin, k=k, **ldist_opts)\n",
    "            for word in words\n",
    "            if force or to_qstr(word) not in db\n",
    "            #and word in {'culture','station','demand'}\n",
    "        ][:lim]#[:3]\n",
    "        iterr=pmap_iter(gen_distmats_,objs, num_proc=num_proc)\n",
    "        for i,(obj,dfdist) in enumerate(zip(objs,iterr)):\n",
    "            #printm('### '+obj['word'])\n",
    "            #display(plot_distmat(dfdist))\n",
    "            db[to_qstr(obj['word'])] = dfdist\n",
    "            if i and not i%10: db.commit()\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd3deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# gen_distmats(lim=10,num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f45c1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# gen_distmats(lim=10,num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0f1932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# gen_distmats(lim=None,num_proc=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc864133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%timeit\n",
    "# gen_distmats(lim=None,num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "963fc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60a123d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# distmat(random.choice(get_valid_words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b2faeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f81649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# dbget('/distmat/vanishing/1720-1900_5/k=10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111c9481-793f-494b-8915-5be9b6bc63d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distmat('virtue',k=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1447ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distmat_(objd): return distmat(**objd)\n",
    "\n",
    "def distmats(words,num_proc=1,progress=True,**distmat_opts):\n",
    "    odf=None\n",
    "    objs=[dict(word=w, progress=False, **distmat_opts) for w in to_words(words)]\n",
    "    iterr=pmap_iter(distmat_, objs, progress=progress, num_proc=num_proc)\n",
    "    for df in iterr:\n",
    "        df=df\n",
    "        if odf is None:\n",
    "            odf=df\n",
    "        else:\n",
    "            df3=pd.concat([odf,df])\n",
    "            odf=df3.groupby(df3.index).mean()\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6870566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_abs_words(vecname='Abs-Conc.Median',cutoff=2):\n",
    "    #df=get_all_signif_changes()\n",
    "    df=get_vector_scores()\n",
    "    s=df.groupby('word').mean()[vecname].sort_values(ascending=False)\n",
    "    return s[s>cutoff].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3667cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfdist = distmats(get_abs_words(), num_proc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7572ffc-422d-438a-9d31-3141532c5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a260c1a0",
   "metadata": {},
   "source": [
    "## Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d8d8bc-7044-4025-b9c8-d0ba7b0f404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w=random.choice(get_valid_words())\n",
    "# test_novelty(distmat(w,num_proc=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5484dea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nov(word_or_words,\n",
    "        num_proc=1, progress=True,\n",
    "        ybin=YBIN_DISTMAT,ymin=YMIN_DISTMAT,ymax=YMAX_DISTMAT,k=K,\n",
    "        force=False,cache_only=False,\n",
    "        **distmat_opts):\n",
    "    #print(f'nov({word_or_words})')\n",
    "    objs_todo=objs=[\n",
    "        dict(\n",
    "            word=w,\n",
    "            qstr=f'{w}/{ymin}-{ymax}_by{ybin}/k={k}',\n",
    "            progress=False,\n",
    "            ybin=ybin,ymax=ymax,ymin=ymin,k=k,\n",
    "            **distmat_opts\n",
    "        ) for w in to_words(word_or_words)\n",
    "    ]\n",
    "    objs_done={}    \n",
    "    if not force:\n",
    "        with get_db('nov',mode='r') as db:\n",
    "            objs_done=dict(\n",
    "                (\n",
    "                    x['qstr'],\n",
    "                    db.get(x['qstr']) if not cache_only else pd.DataFrame(),\n",
    "                )\n",
    "                for x in objs\n",
    "                if x['qstr'] in db\n",
    "            )\n",
    "            objs_todo=[x for x in objs if x['qstr'] not in objs_done]\n",
    "    if len(objs_todo):\n",
    "        objs_done_now={}\n",
    "        iterr=pmap_iter(\n",
    "            nov_word_,\n",
    "            objs_todo,\n",
    "            num_proc=num_proc,\n",
    "            progress=progress\n",
    "        )\n",
    "        with get_db('nov',mode='c') as db:\n",
    "            for i,odf in enumerate(iterr):\n",
    "                if odf is not None and len(odf):\n",
    "                    qstr=odf.iloc[0].qstr\n",
    "                    odf=odf.drop('qstr',1)\n",
    "                    #objs_done_now[qstr]=odf\n",
    "                    db[qstr]=odf\n",
    "                    objs_done[qstr]=odf if not cache_only else pd.DataFrame()\n",
    "                if i and not i%10: db.commit()\n",
    "            db.commit()\n",
    "    return pd.concat(list(objs_done.values()))# if not cache_only else None\n",
    "    \n",
    "        \n",
    "def nov_word(word,qstr=None,**distmat_opts):\n",
    "    try:\n",
    "        odf=test_novelty(distmat(word, **distmat_opts)).assign(\n",
    "            word=word\n",
    "        ).query('foote_novelty!=0').set_index(['word','period'])\n",
    "        if qstr: odf=odf.assign(qstr=qstr)\n",
    "        return odf\n",
    "    except Exception as e:\n",
    "#         print('!!',e)\n",
    "        return pd.DataFrame()\n",
    "def nov_word_(obj): return nov_word(**obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcda7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e243481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28655ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# wl=random.sample(get_valid_words(),10)\n",
    "# !rm ../db/db.kos2.nov.sqlite\n",
    "# nov(wl, num_proc=2, cache_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4c4deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# wl=random.sample(get_valid_words(),10)\n",
    "# !rm ../db/db.kos2.nov.sqlite\n",
    "# nov(wl, num_proc=1, cache_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e476d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# wl=random.sample(get_valid_words(),10)\n",
    "# !rm ../db/db.kos2.nov.sqlite\n",
    "# nov(wl, num_proc=4, cache_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6504b6e0",
   "metadata": {},
   "source": [
    "### Run all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bba369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_novelty_data(words=None,num_proc=4):\n",
    "    if not words: words=get_valid_words()\n",
    "    nov(words, num_proc=num_proc, cache_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "86a9fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# words=get_valid_words()\n",
    "# w=random.choice(words)\n",
    "# nov(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89a4d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# words=get_valid_words()\n",
    "# w=random.choice(words)\n",
    "# distmat(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "608ccecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# words=get_valid_words()\n",
    "# w=random.choice(words)\n",
    "# ldist(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcba49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd920be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
