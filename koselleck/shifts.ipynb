{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (12:37:30) Alles bereit (+0.0s)\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.koselleck import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local neighborhood measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (12:37:30) Running nbr_word(virtue) (+0.0s)\n",
      "[Koselleck] (12:37:30) Finished running nbr_word(virtue) (+0.0s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>cdist</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>period</th>\n",
       "      <th>neighbor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1720-1725</th>\n",
       "      <th>authority</th>\n",
       "      <td>10</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>integrity</th>\n",
       "      <td>10</td>\n",
       "      <td>1.004337</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popish</th>\n",
       "      <td>10</td>\n",
       "      <td>1.055988</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derogatory</th>\n",
       "      <td>10</td>\n",
       "      <td>1.063466</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mankind</th>\n",
       "      <td>10</td>\n",
       "      <td>1.076029</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1895-1900</th>\n",
       "      <th>encouragement</th>\n",
       "      <td>4</td>\n",
       "      <td>1.162844</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lofty</th>\n",
       "      <td>4</td>\n",
       "      <td>1.163750</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>warfare</th>\n",
       "      <td>4</td>\n",
       "      <td>1.163813</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pose</th>\n",
       "      <td>4</td>\n",
       "      <td>1.167160</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perceive</th>\n",
       "      <td>4</td>\n",
       "      <td>1.167461</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count     cdist  rank\n",
       "period    neighbor                            \n",
       "1720-1725 authority         10  0.921875     1\n",
       "          integrity         10  1.004337     2\n",
       "          popish            10  1.055988     3\n",
       "          derogatory        10  1.063466     4\n",
       "          mankind           10  1.076029     5\n",
       "...                        ...       ...   ...\n",
       "1895-1900 encouragement      4  1.162844   996\n",
       "          lofty              4  1.163750   997\n",
       "          warfare            4  1.163813   998\n",
       "          pose               4  1.167160   999\n",
       "          perceive           4  1.167461  1000\n",
       "\n",
       "[36000 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_word('virtue').loc['virtue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lnm_neighborhoods(dfnbr1,dfnbr2,dfcdist1,dfcdist2,k=K,run_all_pairs=False,keep_runs=False,**attrs):\n",
    "    # filter words in both models\n",
    "    valid_words_now=list(set(dfnbr1.index) & set(dfnbr2.index) & set(dfcdist1.columns) & set(dfcdist2.columns))\n",
    "    dfnbr1=dfnbr1.loc[valid_words_now].dropna().sort_values('rank').iloc[:k]\n",
    "    dfnbr2=dfnbr2.loc[valid_words_now].dropna().sort_values('rank').iloc[:k]\n",
    "    dfmetanbr=dfnbr1.append(dfnbr2)\n",
    "    metaneighb=list(set(dfnbr1.index) | set(dfnbr2.index))\n",
    "    dfcdist1=dfcdist1[metaneighb].dropna()\n",
    "    dfcdist2=dfcdist2[metaneighb].dropna()\n",
    "    runs=set(dfcdist1.index) & set(dfcdist2.index)\n",
    "    o=[]\n",
    "    for run1 in runs:\n",
    "        for run2 in runs:\n",
    "            if not run_all_pairs and run1!=run2: continue\n",
    "            if run_all_pairs and run1>run2: continue\n",
    "                \n",
    "            dists1=dfcdist1.loc[run1]\n",
    "            dists2=dfcdist2.loc[run2]\n",
    "            try:\n",
    "                distdists = 1-fastdist.cosine(dists1.values.astype(float), dists2.values.astype(float))\n",
    "            except ZeroDivisionError as e:\n",
    "#                 display(dists1)\n",
    "#                 display(dists2)\n",
    "                print('!!',e)\n",
    "#                 stop\n",
    "                continue\n",
    "            odx={\n",
    "                **attrs,\n",
    "                'run1':run1,\n",
    "                'run2':run2,\n",
    "                'lnm':distdists,\n",
    "                'mneighb_size':len(metaneighb),\n",
    "                'neighb1_size':len(dfnbr1),\n",
    "                'neighb2_size':len(dfnbr2),\n",
    "            }\n",
    "            o.append(odx)\n",
    "    odf=pd.DataFrame(o)\n",
    "    if keep_runs or not len(o): return odf\n",
    "    odf=odf.groupby(list(attrs.keys())).mean().drop(['run1','run2'],1)#.mean()\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lnm_neighborhoods_(objd): return lnm_neighborhoods(**objd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnm_word(\n",
    "        word,\n",
    "        period_or_periods=None,\n",
    "        run_or_runs=None,\n",
    "        word2=None,\n",
    "        cache=True,\n",
    "        force=False,\n",
    "        k=K,\n",
    "        cache_only=False,\n",
    "        progress=True,\n",
    "        progress_nbr=False,\n",
    "        num_proc=1):\n",
    "    word1 = word\n",
    "    if not word2: word2 = word1\n",
    "    qstr=f'{word1},{word2},ymin={YMIN},ymax={YMAX},ybin={YEARBIN},k={k}'\n",
    "    if cache and not force:\n",
    "        with get_veclib('lnm') as vl:\n",
    "            if qstr in vl: return vl[qstr] if not cache_only else pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        dfnbr1 = nbr_word(word1,period_or_periods,run_or_runs,progress=progress_nbr,force=force).loc[word1]\n",
    "        dfnbr2 = dfnbr1 if word2==word1 else nbr_word(word2,period_or_periods,run_or_runs,progress=progress_nbr,force=force).loc[word2]\n",
    "        dfcdist1 = cdist_word(word1,period_or_periods,run_or_runs,progress=progress_nbr).loc[word1]\n",
    "        dfcdist2 = dfcdist1 if word2==word1 else cdist_word(word2,period_or_periods,run_or_runs,progress=progress_nbr).loc[word2]\n",
    "    except KeyError:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "            \n",
    "    periods=sorted(list(\n",
    "        set(dfnbr1.index.get_level_values('period')) | set(dfnbr2.index.get_level_values('period'))\n",
    "    ))\n",
    "    objs = [\n",
    "        dict(\n",
    "            word1=word1,word2=word2,\n",
    "            period1=prd1,period2=prd2,\n",
    "            dfnbr1=dfnbr1.loc[prd1],\n",
    "            dfnbr2=dfnbr2.loc[prd2],\n",
    "            dfcdist1=dfcdist1.loc[prd1],\n",
    "            dfcdist2=dfcdist2.loc[prd2],\n",
    "            k=k\n",
    "        )\n",
    "        for prd1 in periods\n",
    "        for prd2 in periods\n",
    "        if prd1<prd2\n",
    "    ]\n",
    "    if progress: print(f'# of objects: {len(objs)}')\n",
    "    o=pmap(\n",
    "        _lnm_neighborhoods_,\n",
    "        objs,\n",
    "        num_proc=num_proc,\n",
    "        progress=progress,\n",
    "        desc='Measuring LNM across period comparisons'\n",
    "    )\n",
    "    odf=pd.concat(o) if len(o) else pd.DataFrame()\n",
    "    if cache:\n",
    "        with get_veclib('lnm',autocommit=True) as vl:\n",
    "            vl[qstr]=odf\n",
    "    \n",
    "    return odf if not cache_only else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# odf=lnm_word('station',num_proc=1,cache_only=False,force=True,progress_nbr=True)\n",
    "# odf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lnm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lnm_(objd): return lnm_word(**objd)\n",
    "\n",
    "def lnm(\n",
    "        word_or_words,\n",
    "        period_or_periods=None,\n",
    "        run_or_runs=None,\n",
    "        cache=True,\n",
    "        force=False,\n",
    "        cache_only=False,\n",
    "        progress=True,\n",
    "        progress_nbr=False,\n",
    "        progress_word=None,\n",
    "        num_proc=1,\n",
    "        k=K\n",
    "        ):\n",
    "    words=tokenize_fast(word_or_words) if type(word_or_words)==str else list(word_or_words)\n",
    "    \n",
    "    objs=[\n",
    "        dict(\n",
    "            word=word,\n",
    "            period_or_periods=period_or_periods,\n",
    "            run_or_runs=run_or_runs,\n",
    "            word2=None,\n",
    "            cache=cache,\n",
    "            force=force,\n",
    "            k=k,\n",
    "            cache_only=cache_only,\n",
    "            progress=progress_word if progress_word is not None else (False if len(words)>1 else progress),\n",
    "            progress_nbr=progress_nbr,\n",
    "            num_proc=1 if len(words)>1 else num_proc,\n",
    "        ) for word in words\n",
    "    ]\n",
    "    o=pmap(\n",
    "        _lnm_,\n",
    "        objs,\n",
    "        num_proc=num_proc if len(words)>1 else 1,\n",
    "        progress=progress if len(words)>1 else False,\n",
    "        desc='Measuring LNM across words',\n",
    "    )\n",
    "    return pd.concat(o) if len(o) else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lnm('virtue,vice,virtues,vices,values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnm_precache_words(words=None,**y):\n",
    "    words_done=set()\n",
    "    with get_veclib('lnm') as vl:\n",
    "        words_done=set(k.split(',')[0] for k in vl.keys())\n",
    "    if not words: words=get_valid_words()\n",
    "    words=[w for w in words if not w in words_done]\n",
    "    lnm(words, cache_only=True,**y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words=get_valid_words()\n",
    "# random.shuffle(words)\n",
    "# res=pmap(do_word, words, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lnm_precache_words(get_all_nouns_adjs(), num_proc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons of magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10324"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=get_words_with_lnm()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_lnm_word(word,valkey='lnm',min_n=20):\n",
    "    df=lnm_word(word)\n",
    "    if not len(df): return pd.DataFrame()\n",
    "    df=df.loc[word,word].reset_index()\n",
    "    df.period1=df.period1.apply(lambda ystr: periodize_sattelzeit(int(ystr[:4]), use_dates=False))\n",
    "    df.period2=df.period2.apply(lambda ystr: periodize_sattelzeit(int(ystr[:4]), use_dates=False))\n",
    "    df['period_cmp']=[f'{x}-v-{y}' for x,y in zip(df.period1,df.period2)]\n",
    "#     period_cmps={f'{x}-v-{y}' for x,y in zip(df.period1,df.period2) if x!=y}\n",
    "    period_cmps={f'{x}-v-{y}' for x,y in zip(df.period1,df.period2) if x==y}\n",
    "    o=[]\n",
    "    for period_cmp in period_cmps:\n",
    "        g=df[df.period_cmp==period_cmp]\n",
    "        p1,p2=period_cmp.split('-v-')\n",
    "#         gnull=df[df.period_cmp.isin({f'{p1}-v-{p1}', f'{p2}-v-{p2}'})]\n",
    "        gnull=df[(df.period_cmp!=period_cmp) & df.period_cmp.isin(period_cmps)]\n",
    "        a=gnull[valkey]\n",
    "        b=g[valkey]\n",
    "        if len(a)<min_n or len(b)<min_n: continue\n",
    "        mw,mw_p=mannwhitneyu(a,b)\n",
    "        o+=[dict(\n",
    "            word=word,\n",
    "            vector='LNM',\n",
    "            period_cmp=period_cmp,\n",
    "            n1=len(a),\n",
    "            n2=len(b),\n",
    "            mw=mw,\n",
    "            mw_p=mw_p,\n",
    "            avg1=a.mean(),\n",
    "            avg2=b.mean(),\n",
    "        )]\n",
    "    df=pd.DataFrame(o)\n",
    "#     if len(df):\n",
    "#         df['avg_diff']=df.avg2 - df.avg1\n",
    "#         df['avg_div']=df.avg2/df.avg1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "      <th>period_cmp</th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>mw</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>avg1</th>\n",
       "      <th>avg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>LNM</td>\n",
       "      <td>During-v-During</td>\n",
       "      <td>93</td>\n",
       "      <td>66</td>\n",
       "      <td>738.0</td>\n",
       "      <td>1.874428e-16</td>\n",
       "      <td>0.025309</td>\n",
       "      <td>0.045749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sympathy</td>\n",
       "      <td>LNM</td>\n",
       "      <td>After-v-After</td>\n",
       "      <td>68</td>\n",
       "      <td>91</td>\n",
       "      <td>705.0</td>\n",
       "      <td>4.573953e-17</td>\n",
       "      <td>0.045641</td>\n",
       "      <td>0.024940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word vector       period_cmp  n1  n2     mw          mw_p      avg1  \\\n",
       "0  sympathy    LNM  During-v-During  93  66  738.0  1.874428e-16  0.025309   \n",
       "1  sympathy    LNM    After-v-After  68  91  705.0  4.573953e-17  0.045641   \n",
       "\n",
       "       avg2  \n",
       "0  0.045749  \n",
       "1  0.024940  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_lnm_word('sympathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_lnm_words(force=False,num_proc=1):\n",
    "    if not force and os.path.exists(FN_LNM_TTEST): return read_df(FN_LNM_TTEST)\n",
    "    \n",
    "    words=get_words_with_lnm()\n",
    "    o=pmap(\n",
    "        ttest_lnm_word,\n",
    "        words,\n",
    "        num_proc=num_proc\n",
    "    )\n",
    "    if not len(o): return pd.DataFrame()\n",
    "    odf=pd.concat(o) if len(o) else pd.DataFrame()\n",
    "    odf['mw_perc']=odf.mw.rank(ascending=False) / len(odf) * 100\n",
    "    odf=odf.set_index(['word','vector','period_cmp']).sort_values('mw')\n",
    "    odf=pd.concat(\n",
    "        vdf.assign(mw_perc_vec=vdf.mw.rank(ascending=False) / len(vdf) * 100)\n",
    "        for i,vdf in odf.groupby('vector')\n",
    "    )\n",
    "    odf=pd.concat(\n",
    "        vdf.assign(mw_perc_vec_cmp=vdf.mw.rank(ascending=False) / len(vdf) * 100)\n",
    "        for i,vdf in odf.groupby(['vector','period_cmp'])\n",
    "    )\n",
    "    odf=pd.concat(\n",
    "        vdf.assign(\n",
    "            avg1_perc_vec=(vdf.avg1.rank(ascending=False) / len(vdf) * 100),\n",
    "            avg2_perc_vec=(vdf.avg2.rank(ascending=False) / len(vdf) * 100),\n",
    "        )\n",
    "        for i,vdf in odf.groupby('vector')\n",
    "    )\n",
    "    \n",
    "    odf=odf.sort_index()\n",
    "    s=odf.avg1.append(odf.avg2)\n",
    "    odf.avg1 = (odf.avg1 - s.mean())/s.std()\n",
    "    odf.avg2 = (odf.avg2 - s.mean())/s.std()\n",
    "    odf['avg_diff']=odf.avg2 - odf.avg1\n",
    "    odf['avg_div']=odf.avg2/odf.avg1\n",
    "    \n",
    "    odf.to_pickle(FN_LNM_TTEST)\n",
    "    \n",
    "    # add to db\n",
    "    with get_veclib('ttest_lnm') as vl:\n",
    "        for w,wdf in tqdm(odf.groupby('word'),desc='Adding to db'):\n",
    "            vl[w]=wdf\n",
    "        print('Committing')\n",
    "        vl.commit()\n",
    "        print('Done')\n",
    "    \n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping ttest_lnm_word() [x4]: 100%|██████████| 10324/10324 [00:24<00:00, 425.30it/s]\n",
      "Adding to db: 100%|██████████| 5347/5347 [00:05<00:00, 949.86it/s] \n",
      "[Koselleck] (12:47:02) Committing (+349.8s)\n",
      "[Koselleck] (12:47:02) Done (+0.3s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>mw</th>\n",
       "      <th>mw_p</th>\n",
       "      <th>avg1</th>\n",
       "      <th>avg2</th>\n",
       "      <th>mw_perc</th>\n",
       "      <th>mw_perc_vec</th>\n",
       "      <th>mw_perc_vec_cmp</th>\n",
       "      <th>avg1_perc_vec</th>\n",
       "      <th>avg2_perc_vec</th>\n",
       "      <th>avg_diff</th>\n",
       "      <th>avg_div</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "      <th>period_cmp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">abbe</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LNM</th>\n",
       "      <th>Before-v-Before</th>\n",
       "      <td>61</td>\n",
       "      <td>43</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>2.379579e-01</td>\n",
       "      <td>0.910807</td>\n",
       "      <td>0.969635</td>\n",
       "      <td>73.653576</td>\n",
       "      <td>73.653576</td>\n",
       "      <td>61.223292</td>\n",
       "      <td>12.952314</td>\n",
       "      <td>15.701262</td>\n",
       "      <td>0.058828</td>\n",
       "      <td>1.064589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>During-v-During</th>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>4.264494e-01</td>\n",
       "      <td>0.895216</td>\n",
       "      <td>0.972088</td>\n",
       "      <td>69.814165</td>\n",
       "      <td>69.814165</td>\n",
       "      <td>78.477842</td>\n",
       "      <td>13.267882</td>\n",
       "      <td>15.659187</td>\n",
       "      <td>0.076872</td>\n",
       "      <td>1.085870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">abbey</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">LNM</th>\n",
       "      <th>After-v-After</th>\n",
       "      <td>111</td>\n",
       "      <td>91</td>\n",
       "      <td>3702.0</td>\n",
       "      <td>5.551074e-04</td>\n",
       "      <td>1.209284</td>\n",
       "      <td>0.593787</td>\n",
       "      <td>12.338710</td>\n",
       "      <td>12.338710</td>\n",
       "      <td>13.302848</td>\n",
       "      <td>9.011220</td>\n",
       "      <td>22.706872</td>\n",
       "      <td>-0.615497</td>\n",
       "      <td>0.491023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before-v-Before</th>\n",
       "      <td>157</td>\n",
       "      <td>45</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>5.309801e-07</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>1.909350</td>\n",
       "      <td>54.330295</td>\n",
       "      <td>54.330295</td>\n",
       "      <td>33.916412</td>\n",
       "      <td>17.847125</td>\n",
       "      <td>6.100982</td>\n",
       "      <td>1.257475</td>\n",
       "      <td>2.929012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>During-v-During</th>\n",
       "      <td>136</td>\n",
       "      <td>66</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>1.925111e-01</td>\n",
       "      <td>1.029084</td>\n",
       "      <td>0.731967</td>\n",
       "      <td>5.599579</td>\n",
       "      <td>5.599579</td>\n",
       "      <td>8.256262</td>\n",
       "      <td>11.241234</td>\n",
       "      <td>19.775596</td>\n",
       "      <td>-0.297117</td>\n",
       "      <td>0.711280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">zealous</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">LNM</th>\n",
       "      <th>After-v-After</th>\n",
       "      <td>111</td>\n",
       "      <td>87</td>\n",
       "      <td>4091.0</td>\n",
       "      <td>3.276214e-02</td>\n",
       "      <td>-0.116929</td>\n",
       "      <td>-0.386408</td>\n",
       "      <td>6.367461</td>\n",
       "      <td>6.367461</td>\n",
       "      <td>8.522137</td>\n",
       "      <td>45.140252</td>\n",
       "      <td>59.438990</td>\n",
       "      <td>-0.269479</td>\n",
       "      <td>3.304645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Before-v-Before</th>\n",
       "      <td>153</td>\n",
       "      <td>45</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>6.064750e-07</td>\n",
       "      <td>-0.416172</td>\n",
       "      <td>0.379506</td>\n",
       "      <td>55.504909</td>\n",
       "      <td>55.504909</td>\n",
       "      <td>35.407373</td>\n",
       "      <td>62.005610</td>\n",
       "      <td>28.022440</td>\n",
       "      <td>0.795678</td>\n",
       "      <td>-0.911897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>During-v-During</th>\n",
       "      <td>132</td>\n",
       "      <td>66</td>\n",
       "      <td>3453.0</td>\n",
       "      <td>8.788946e-03</td>\n",
       "      <td>-0.125301</td>\n",
       "      <td>-0.455407</td>\n",
       "      <td>16.746143</td>\n",
       "      <td>16.746143</td>\n",
       "      <td>29.431599</td>\n",
       "      <td>45.476858</td>\n",
       "      <td>63.288920</td>\n",
       "      <td>-0.330106</td>\n",
       "      <td>3.634509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">zoo</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">LNM</th>\n",
       "      <th>Before-v-Before</th>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>516.0</td>\n",
       "      <td>4.948288e-01</td>\n",
       "      <td>1.430636</td>\n",
       "      <td>1.619306</td>\n",
       "      <td>93.425666</td>\n",
       "      <td>93.425666</td>\n",
       "      <td>91.195116</td>\n",
       "      <td>6.612903</td>\n",
       "      <td>8.239832</td>\n",
       "      <td>0.188671</td>\n",
       "      <td>1.131879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>During-v-During</th>\n",
       "      <td>47</td>\n",
       "      <td>21</td>\n",
       "      <td>449.0</td>\n",
       "      <td>2.795887e-01</td>\n",
       "      <td>1.673938</td>\n",
       "      <td>1.290395</td>\n",
       "      <td>95.084151</td>\n",
       "      <td>95.084151</td>\n",
       "      <td>95.491329</td>\n",
       "      <td>4.824684</td>\n",
       "      <td>11.346424</td>\n",
       "      <td>-0.383544</td>\n",
       "      <td>0.770873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14260 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 n1  n2      mw          mw_p      avg1  \\\n",
       "word    vector period_cmp                                                 \n",
       "abbe    LNM    Before-v-Before   61  43  1203.0  2.379579e-01  0.910807   \n",
       "               During-v-During   50  54  1321.0  4.264494e-01  0.895216   \n",
       "abbey   LNM    After-v-After    111  91  3702.0  5.551074e-04  1.209284   \n",
       "               Before-v-Before  157  45  1845.0  5.309801e-07  0.651875   \n",
       "               During-v-During  136  66  4149.0  1.925111e-01  1.029084   \n",
       "...                             ...  ..     ...           ...       ...   \n",
       "zealous LNM    After-v-After    111  87  4091.0  3.276214e-02 -0.116929   \n",
       "               Before-v-Before  153  45  1802.0  6.064750e-07 -0.416172   \n",
       "               During-v-During  132  66  3453.0  8.788946e-03 -0.125301   \n",
       "zoo     LNM    Before-v-Before   23  45   516.0  4.948288e-01  1.430636   \n",
       "               During-v-During   47  21   449.0  2.795887e-01  1.673938   \n",
       "\n",
       "                                    avg2    mw_perc  mw_perc_vec  \\\n",
       "word    vector period_cmp                                          \n",
       "abbe    LNM    Before-v-Before  0.969635  73.653576    73.653576   \n",
       "               During-v-During  0.972088  69.814165    69.814165   \n",
       "abbey   LNM    After-v-After    0.593787  12.338710    12.338710   \n",
       "               Before-v-Before  1.909350  54.330295    54.330295   \n",
       "               During-v-During  0.731967   5.599579     5.599579   \n",
       "...                                  ...        ...          ...   \n",
       "zealous LNM    After-v-After   -0.386408   6.367461     6.367461   \n",
       "               Before-v-Before  0.379506  55.504909    55.504909   \n",
       "               During-v-During -0.455407  16.746143    16.746143   \n",
       "zoo     LNM    Before-v-Before  1.619306  93.425666    93.425666   \n",
       "               During-v-During  1.290395  95.084151    95.084151   \n",
       "\n",
       "                                mw_perc_vec_cmp  avg1_perc_vec  avg2_perc_vec  \\\n",
       "word    vector period_cmp                                                       \n",
       "abbe    LNM    Before-v-Before        61.223292      12.952314      15.701262   \n",
       "               During-v-During        78.477842      13.267882      15.659187   \n",
       "abbey   LNM    After-v-After          13.302848       9.011220      22.706872   \n",
       "               Before-v-Before        33.916412      17.847125       6.100982   \n",
       "               During-v-During         8.256262      11.241234      19.775596   \n",
       "...                                         ...            ...            ...   \n",
       "zealous LNM    After-v-After           8.522137      45.140252      59.438990   \n",
       "               Before-v-Before        35.407373      62.005610      28.022440   \n",
       "               During-v-During        29.431599      45.476858      63.288920   \n",
       "zoo     LNM    Before-v-Before        91.195116       6.612903       8.239832   \n",
       "               During-v-During        95.491329       4.824684      11.346424   \n",
       "\n",
       "                                avg_diff   avg_div  \n",
       "word    vector period_cmp                           \n",
       "abbe    LNM    Before-v-Before  0.058828  1.064589  \n",
       "               During-v-During  0.076872  1.085870  \n",
       "abbey   LNM    After-v-After   -0.615497  0.491023  \n",
       "               Before-v-Before  1.257475  2.929012  \n",
       "               During-v-During -0.297117  0.711280  \n",
       "...                                  ...       ...  \n",
       "zealous LNM    After-v-After   -0.269479  3.304645  \n",
       "               Before-v-Before  0.795678 -0.911897  \n",
       "               During-v-During -0.330106  3.634509  \n",
       "zoo     LNM    Before-v-Before  0.188671  1.131879  \n",
       "               During-v-During -0.383544  0.770873  \n",
       "\n",
       "[14260 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf=ttest_lnm_words(num_proc=4,force=True)\n",
    "odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
