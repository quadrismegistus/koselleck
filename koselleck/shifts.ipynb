{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.koselleck import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local neighborhood measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w='station'\n",
    "\n",
    "YBIN_NBR=20\n",
    "YMIN_NBR=1700\n",
    "YMAX_NBR=1900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfnbr=nbr_word(w,ybin=YBIN_NBR,ymin=YMIN_NBR,ymax=YMAX_NBR,force=False,num_proc=4).reset_index()\n",
    "# dfnbr['period_len']=[int(x[-4:]) - int(x[:4]) for x in dfnbr.period]\n",
    "# dfnbr.period_len.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (11:35:03) Finished running cdist_word(station) (+6.6s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbe</th>\n",
       "      <th>abbess</th>\n",
       "      <th>abbey</th>\n",
       "      <th>...</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zephyr</th>\n",
       "      <th>zest</th>\n",
       "      <th>zinc</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoological</th>\n",
       "      <th>zoology</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_</th>\n",
       "      <th>period_</th>\n",
       "      <th>run_</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">station</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1700-1705</th>\n",
       "      <th>1</th>\n",
       "      <td>0.948871</td>\n",
       "      <td>0.918744</td>\n",
       "      <td>0.955560</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982695</td>\n",
       "      <td>0.856937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.132782</td>\n",
       "      <td>0.909438</td>\n",
       "      <td>1.042427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871096</td>\n",
       "      <td>0.692374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.092415</td>\n",
       "      <td>0.950319</td>\n",
       "      <td>0.966035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.944321</td>\n",
       "      <td>0.632112</td>\n",
       "      <td>1.068780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.867493</td>\n",
       "      <td>0.935139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916769</td>\n",
       "      <td>0.790399</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.097515</td>\n",
       "      <td>1.052195</td>\n",
       "      <td>0.854973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933849</td>\n",
       "      <td>0.922525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.071947</td>\n",
       "      <td>0.870604</td>\n",
       "      <td>0.966253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983929</td>\n",
       "      <td>0.741790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.842233</td>\n",
       "      <td>0.937062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.812107</td>\n",
       "      <td>0.920732</td>\n",
       "      <td>1.032329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.892790</td>\n",
       "      <td>1.228177</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903570</td>\n",
       "      <td>0.658214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.039314</td>\n",
       "      <td>0.966896</td>\n",
       "      <td>0.908350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941186</td>\n",
       "      <td>0.880589</td>\n",
       "      <td>1.070103</td>\n",
       "      <td>1.095534</td>\n",
       "      <td>0.972781</td>\n",
       "      <td>1.080854</td>\n",
       "      <td>...</td>\n",
       "      <td>1.077262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.890637</td>\n",
       "      <td>0.735945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1895-1900</th>\n",
       "      <th>6</th>\n",
       "      <td>1.301627</td>\n",
       "      <td>0.880815</td>\n",
       "      <td>1.116048</td>\n",
       "      <td>1.026179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.613744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.367641</td>\n",
       "      <td>0.936883</td>\n",
       "      <td>0.834988</td>\n",
       "      <td>1.091117</td>\n",
       "      <td>0.784255</td>\n",
       "      <td>0.806932</td>\n",
       "      <td>0.786050</td>\n",
       "      <td>0.829083</td>\n",
       "      <td>0.885881</td>\n",
       "      <td>0.853985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.017823</td>\n",
       "      <td>1.078721</td>\n",
       "      <td>0.835061</td>\n",
       "      <td>1.007609</td>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.899824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.580467</td>\n",
       "      <td>0.755247</td>\n",
       "      <td>0.538175</td>\n",
       "      <td>...</td>\n",
       "      <td>1.164052</td>\n",
       "      <td>0.753413</td>\n",
       "      <td>1.215511</td>\n",
       "      <td>1.056076</td>\n",
       "      <td>0.908829</td>\n",
       "      <td>0.761987</td>\n",
       "      <td>0.762617</td>\n",
       "      <td>0.745856</td>\n",
       "      <td>1.144429</td>\n",
       "      <td>0.989870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.052353</td>\n",
       "      <td>0.993460</td>\n",
       "      <td>0.925477</td>\n",
       "      <td>0.783007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840540</td>\n",
       "      <td>1.142362</td>\n",
       "      <td>0.859709</td>\n",
       "      <td>0.843648</td>\n",
       "      <td>0.595659</td>\n",
       "      <td>...</td>\n",
       "      <td>1.114407</td>\n",
       "      <td>0.836680</td>\n",
       "      <td>0.837813</td>\n",
       "      <td>1.104225</td>\n",
       "      <td>0.711716</td>\n",
       "      <td>0.872090</td>\n",
       "      <td>0.691038</td>\n",
       "      <td>0.719671</td>\n",
       "      <td>1.062151</td>\n",
       "      <td>0.903872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.078712</td>\n",
       "      <td>1.081699</td>\n",
       "      <td>0.855514</td>\n",
       "      <td>1.067983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980951</td>\n",
       "      <td>0.753701</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.114454</td>\n",
       "      <td>0.943961</td>\n",
       "      <td>1.073956</td>\n",
       "      <td>1.161853</td>\n",
       "      <td>0.991612</td>\n",
       "      <td>0.739279</td>\n",
       "      <td>0.846314</td>\n",
       "      <td>0.700322</td>\n",
       "      <td>0.978648</td>\n",
       "      <td>0.706634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.038328</td>\n",
       "      <td>0.985189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.133934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006114</td>\n",
       "      <td>0.757747</td>\n",
       "      <td>0.844385</td>\n",
       "      <td>0.850136</td>\n",
       "      <td>0.662767</td>\n",
       "      <td>...</td>\n",
       "      <td>1.153319</td>\n",
       "      <td>0.870763</td>\n",
       "      <td>0.831703</td>\n",
       "      <td>0.921027</td>\n",
       "      <td>0.774325</td>\n",
       "      <td>0.821564</td>\n",
       "      <td>0.885272</td>\n",
       "      <td>0.801627</td>\n",
       "      <td>0.980594</td>\n",
       "      <td>0.848405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 15513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         abandon  abandoned  abandoning  abandonment  \\\n",
       "word_   period_   run_                                                 \n",
       "station 1700-1705 1     0.948871   0.918744    0.955560          NaN   \n",
       "                  2     1.092415   0.950319    0.966035          NaN   \n",
       "                  3     1.097515   1.052195    0.854973          NaN   \n",
       "                  4     0.918367   0.842233    0.937062          NaN   \n",
       "                  5     1.039314   0.966896    0.908350          NaN   \n",
       "...                          ...        ...         ...          ...   \n",
       "        1895-1900 6     1.301627   0.880815    1.116048     1.026179   \n",
       "                  7     1.017823   1.078721    0.835061     1.007609   \n",
       "                  8     1.052353   0.993460    0.925477     0.783007   \n",
       "                  9     1.078712   1.081699    0.855514     1.067983   \n",
       "                  10    1.038328   0.985189         NaN     1.133934   \n",
       "\n",
       "                           abate    abated  abatement      abbe    abbess  \\\n",
       "word_   period_   run_                                                      \n",
       "station 1700-1705 1     0.982695  0.856937        NaN  1.132782  0.909438   \n",
       "                  2     0.944321  0.632112   1.068780       NaN  0.867493   \n",
       "                  3     0.933849  0.922525        NaN  1.071947  0.870604   \n",
       "                  4     0.812107  0.920732   1.032329       NaN  0.892790   \n",
       "                  5     0.941186  0.880589   1.070103  1.095534  0.972781   \n",
       "...                          ...       ...        ...       ...       ...   \n",
       "        1895-1900 6          NaN  0.784317        NaN  0.912622       NaN   \n",
       "                  7     0.819167  0.899824        NaN  0.580467  0.755247   \n",
       "                  8          NaN  0.840540   1.142362  0.859709  0.843648   \n",
       "                  9          NaN  1.014848        NaN  0.980951  0.753701   \n",
       "                  10         NaN  1.006114   0.757747  0.844385  0.850136   \n",
       "\n",
       "                           abbey  ...   zealous    zenith    zephyr      zest  \\\n",
       "word_   period_   run_            ...                                           \n",
       "station 1700-1705 1     1.042427  ...  0.885291       NaN       NaN       NaN   \n",
       "                  2     0.935139  ...  0.998856       NaN       NaN       NaN   \n",
       "                  3     0.966253  ...  0.860833       NaN       NaN       NaN   \n",
       "                  4     1.228177  ...  1.036336       NaN       NaN       NaN   \n",
       "                  5     1.080854  ...  1.077262       NaN       NaN       NaN   \n",
       "...                          ...  ...       ...       ...       ...       ...   \n",
       "        1895-1900 6     0.613744  ...  1.367641  0.936883  0.834988  1.091117   \n",
       "                  7     0.538175  ...  1.164052  0.753413  1.215511  1.056076   \n",
       "                  8     0.595659  ...  1.114407  0.836680  0.837813  1.104225   \n",
       "                  9     0.637230  ...  1.114454  0.943961  1.073956  1.161853   \n",
       "                  10    0.662767  ...  1.153319  0.870763  0.831703  0.921027   \n",
       "\n",
       "                            zinc      zone       zoo  zoological   zoology  \\\n",
       "word_   period_   run_                                                       \n",
       "station 1700-1705 1          NaN  0.871096  0.692374         NaN       NaN   \n",
       "                  2          NaN  0.916769  0.790399         NaN       NaN   \n",
       "                  3          NaN  0.983929  0.741790         NaN       NaN   \n",
       "                  4          NaN  0.903570  0.658214         NaN       NaN   \n",
       "                  5          NaN  0.890637  0.735945         NaN       NaN   \n",
       "...                          ...       ...       ...         ...       ...   \n",
       "        1895-1900 6     0.784255  0.806932  0.786050    0.829083  0.885881   \n",
       "                  7     0.908829  0.761987  0.762617    0.745856  1.144429   \n",
       "                  8     0.711716  0.872090  0.691038    0.719671  1.062151   \n",
       "                  9     0.991612  0.739279  0.846314    0.700322  0.978648   \n",
       "                  10    0.774325  0.821564  0.885272    0.801627  0.980594   \n",
       "\n",
       "                            zulu  \n",
       "word_   period_   run_            \n",
       "station 1700-1705 1          NaN  \n",
       "                  2          NaN  \n",
       "                  3          NaN  \n",
       "                  4          NaN  \n",
       "                  5          NaN  \n",
       "...                          ...  \n",
       "        1895-1900 6     0.853985  \n",
       "                  7     0.989870  \n",
       "                  8     0.903872  \n",
       "                  9     0.706634  \n",
       "                  10    0.848405  \n",
       "\n",
       "[400 rows x 15513 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcdist=cdist_word(w,ybin=5,num_proc=4)\n",
    "dfcdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfcdist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lnm_neighborhoods(\n",
    "        #dfnbr1,\n",
    "        #dfnbr2,\n",
    "        dfcdist1,\n",
    "        dfcdist2,\n",
    "        k=K,\n",
    "        run_all_pairs=False,\n",
    "        min_size=None,\n",
    "        keep_runs=False,\n",
    "        incl_words=False,\n",
    "        **attrs):\n",
    "    # filter words in both models\n",
    "    s1=dfcdist1.mean().dropna()\n",
    "    s2=dfcdist2.mean().dropna()\n",
    "    valid_words_now=set(s1.index) & set(s2.index)\n",
    "    s1=s1.loc[valid_words_now].sort_values()\n",
    "    s2=s2.loc[valid_words_now].sort_values()\n",
    "    \n",
    "    # get top words for each\n",
    "    nb1=s1.iloc[:k].index\n",
    "    nb2=s2.iloc[:k].index\n",
    "    \n",
    "    # get meta neighborhoods\n",
    "    mnb=list(set(nb1)|set(nb2))\n",
    "    nb1s=s1.loc[mnb]\n",
    "    nb2s=s2.loc[mnb]\n",
    "    \n",
    "    # try to get distance\n",
    "    try:\n",
    "        distdists = 1-fastdist.cosine(nb1s.values.astype(float), nb2s.values.astype(float))\n",
    "    except ZeroDivisionError as e:\n",
    "        distdists=np.nan\n",
    "        \n",
    "    # return dict as df\n",
    "    odx={\n",
    "        **attrs,\n",
    "        'lnm':distdists,\n",
    "        'mneighb_size':len(mnb),\n",
    "        'neighb1_size':len(nb1),\n",
    "        'neighb2_size':len(nb2),\n",
    "        'neighb1':', '.join(nb1) if incl_words else '',\n",
    "        'neighb2':', '.join(nb2) if incl_words else '',\n",
    "    }\n",
    "    odf=pd.DataFrame([odx])\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lnm_neighborhoods_(objd): return lnm_neighborhoods(**objd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lnm_word('culture',ymin=1700,ymax=1900,ybin=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnm_word(\n",
    "        word,\n",
    "        period_or_periods=None,\n",
    "        run_or_runs=None,\n",
    "        num_runs=10,\n",
    "        word2=None,\n",
    "        cache=True,\n",
    "        force=False,\n",
    "        k=K,\n",
    "        cache_only=False,\n",
    "        progress=True,\n",
    "        progress_nbr=True,\n",
    "        ymin=YMIN_DISTMAT,\n",
    "        ymax=YMAX_NBR,\n",
    "        ybin=YBIN_NBR,\n",
    "        num_proc=1,\n",
    "        incl_words=False):\n",
    "    qstr=f'{word},ymin={ymin},ymax={ymax},ybin={ybin},k={k}'\n",
    "    if cache and not force:\n",
    "        with get_veclib('lnm') as vl:\n",
    "            if qstr in vl: return vl[qstr] if not cache_only else pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        dfcdist = cdist_word(\n",
    "            word,period_or_periods,run_or_runs,\n",
    "            num_runs=num_runs,\n",
    "            progress=progress_nbr,num_proc=num_proc,force=force,\n",
    "            ymin=ymin,ymax=ymax,ybin=ybin\n",
    "        ).loc[word]\n",
    "    except KeyError:\n",
    "        return pd.DataFrame()\n",
    "    dfcdists_prds = list(dfcdist.groupby('period_'))\n",
    "    objs = [\n",
    "        dict(\n",
    "            word=word,\n",
    "            period1=prd1,period2=prd2,\n",
    "#             dfnbr1=dfnbr1.loc[prd1],\n",
    "#             dfnbr2=dfnbr2.loc[prd2],\n",
    "            dfcdist1=dfprd1,\n",
    "            dfcdist2=dfprd2,\n",
    "            k=k,\n",
    "            incl_words=incl_words,\n",
    "        )\n",
    "        for prd1,dfprd1 in dfcdists_prds\n",
    "        for prd2,dfprd2 in dfcdists_prds\n",
    "        if prd1<prd2\n",
    "    ]\n",
    "    o=pmap(\n",
    "        _lnm_neighborhoods_,\n",
    "        objs,\n",
    "        num_proc=num_proc,\n",
    "        progress=progress,\n",
    "        desc='[Koselleck] Measuring LNM across period comparisons'\n",
    "    )\n",
    "    odf=pd.concat(o) if len(o) else pd.DataFrame()\n",
    "    if cache:\n",
    "        with get_veclib('lnm',autocommit=True) as vl:\n",
    "            vl[qstr]=odf\n",
    "    \n",
    "    return odf if not cache_only else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Koselleck] (11:56:45) Finished running cdist_word(virtue) (+18.9s)\n",
      "[Koselleck] Measuring LNM across period comparisons [x4]: 100%|██████████| 630/630 [00:37<00:00, 16.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "word                                                                                                          virtue\n",
       "period1                                                                                                    1720-1725\n",
       "period2                                                                                                    1725-1730\n",
       "lnm                                                                                                        0.0456996\n",
       "mneighb_size                                                                                                      20\n",
       "neighb1_size                                                                                                      10\n",
       "neighb2_size                                                                                                      10\n",
       "neighb1         authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption\n",
       "neighb2              misfortunes, benevolence, actions, absolute, experience, riches, moral, minds, merit, abilities\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf=lnm_word('virtue',num_proc=4,force=True,ybin=5,incl_words=True,k=10)\n",
    "odf.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>period1</th>\n",
       "      <th>period2</th>\n",
       "      <th>lnm</th>\n",
       "      <th>mneighb_size</th>\n",
       "      <th>neighb1_size</th>\n",
       "      <th>neighb2_size</th>\n",
       "      <th>neighb1</th>\n",
       "      <th>neighb2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1855-1860</td>\n",
       "      <td>1860-1865</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>wisdom, spiritual, holiness, morality, moral, religion, piety, divine, faith, goodness</td>\n",
       "      <td>wisdom, spiritual, moral, piety, goodness, holiness, faith, humanity, creator, morality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1885-1890</td>\n",
       "      <td>1890-1895</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>humanity, wisdom, faith, instinct, moral, spiritual, intellect, belief, morality, freedom</td>\n",
       "      <td>moral, humanity, wisdom, spiritual, instinct, belief, nature, intellect, religion, faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1865-1870</td>\n",
       "      <td>1880-1885</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>humanity, wisdom, spiritual, moral, intellect, morality, religion, sacrifice, piety, mankind</td>\n",
       "      <td>humanity, wisdom, spiritual, moral, faith, devotion, morality, divine, sacrifice, intellect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1755-1760</td>\n",
       "      <td>1790-1795</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>virtuous, piety, wisdom, benevolence, social, goodness, folly, happiness, humanity, pride</td>\n",
       "      <td>virtuous, piety, wisdom, happiness, social, benevolence, humanity, mankind, folly, pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1755-1760</td>\n",
       "      <td>1805-1810</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>virtuous, piety, wisdom, benevolence, social, goodness, folly, happiness, humanity, pride</td>\n",
       "      <td>virtuous, piety, benevolence, wisdom, humanity, folly, social, mankind, happiness, pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1720-1725</td>\n",
       "      <td>1780-1785</td>\n",
       "      <td>0.138657</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption</td>\n",
       "      <td>virtuous, benevolence, ambition, pride, piety, innocence, virtues, wisdom, humanity, greatness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1720-1725</td>\n",
       "      <td>1795-1800</td>\n",
       "      <td>0.140057</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption</td>\n",
       "      <td>virtuous, benevolence, piety, wisdom, mankind, humanity, social, rational, virtues, exalted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1720-1725</td>\n",
       "      <td>1800-1805</td>\n",
       "      <td>0.142183</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption</td>\n",
       "      <td>wisdom, virtuous, benevolence, humanity, piety, social, mankind, virtues, generous, happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1720-1725</td>\n",
       "      <td>1805-1810</td>\n",
       "      <td>0.143349</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption</td>\n",
       "      <td>virtuous, piety, benevolence, wisdom, humanity, folly, social, mankind, happiness, pride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>virtue</td>\n",
       "      <td>1785-1790</td>\n",
       "      <td>1890-1895</td>\n",
       "      <td>0.143425</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>virtuous, piety, benevolence, wisdom, humanity, folly, exalted, prudence, mankind, goodness</td>\n",
       "      <td>moral, humanity, wisdom, spiritual, instinct, belief, nature, intellect, religion, faith</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word    period1    period2       lnm  mneighb_size  neighb1_size  \\\n",
       "0   virtue  1855-1860  1860-1865  0.000360            12            10   \n",
       "0   virtue  1885-1890  1890-1895  0.001471            12            10   \n",
       "0   virtue  1865-1870  1880-1885  0.001597            13            10   \n",
       "0   virtue  1755-1760  1790-1795  0.001883            11            10   \n",
       "0   virtue  1755-1760  1805-1810  0.001931            11            10   \n",
       "..     ...        ...        ...       ...           ...           ...   \n",
       "0   virtue  1720-1725  1780-1785  0.138657            20            10   \n",
       "0   virtue  1720-1725  1795-1800  0.140057            19            10   \n",
       "0   virtue  1720-1725  1800-1805  0.142183            19            10   \n",
       "0   virtue  1720-1725  1805-1810  0.143349            19            10   \n",
       "0   virtue  1785-1790  1890-1895  0.143425            18            10   \n",
       "\n",
       "    neighb2_size  \\\n",
       "0             10   \n",
       "0             10   \n",
       "0             10   \n",
       "0             10   \n",
       "0             10   \n",
       "..           ...   \n",
       "0             10   \n",
       "0             10   \n",
       "0             10   \n",
       "0             10   \n",
       "0             10   \n",
       "\n",
       "                                                                                                 neighb1  \\\n",
       "0                 wisdom, spiritual, holiness, morality, moral, religion, piety, divine, faith, goodness   \n",
       "0              humanity, wisdom, faith, instinct, moral, spiritual, intellect, belief, morality, freedom   \n",
       "0           humanity, wisdom, spiritual, moral, intellect, morality, religion, sacrifice, piety, mankind   \n",
       "0              virtuous, piety, wisdom, benevolence, social, goodness, folly, happiness, humanity, pride   \n",
       "0              virtuous, piety, wisdom, benevolence, social, goodness, folly, happiness, humanity, pride   \n",
       "..                                                                                                   ...   \n",
       "0   authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption   \n",
       "0   authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption   \n",
       "0   authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption   \n",
       "0   authority, integrity, popish, mankind, privileges, prejudice, sense, privilege, property, corruption   \n",
       "0            virtuous, piety, benevolence, wisdom, humanity, folly, exalted, prudence, mankind, goodness   \n",
       "\n",
       "                                                                                           neighb2  \n",
       "0          wisdom, spiritual, moral, piety, goodness, holiness, faith, humanity, creator, morality  \n",
       "0         moral, humanity, wisdom, spiritual, instinct, belief, nature, intellect, religion, faith  \n",
       "0      humanity, wisdom, spiritual, moral, faith, devotion, morality, divine, sacrifice, intellect  \n",
       "0         virtuous, piety, wisdom, happiness, social, benevolence, humanity, mankind, folly, pride  \n",
       "0         virtuous, piety, benevolence, wisdom, humanity, folly, social, mankind, happiness, pride  \n",
       "..                                                                                             ...  \n",
       "0   virtuous, benevolence, ambition, pride, piety, innocence, virtues, wisdom, humanity, greatness  \n",
       "0      virtuous, benevolence, piety, wisdom, mankind, humanity, social, rational, virtues, exalted  \n",
       "0    wisdom, virtuous, benevolence, humanity, piety, social, mankind, virtues, generous, happiness  \n",
       "0         virtuous, piety, benevolence, wisdom, humanity, folly, social, mankind, happiness, pride  \n",
       "0         moral, humanity, wisdom, spiritual, instinct, belief, nature, intellect, religion, faith  \n",
       "\n",
       "[630 rows x 9 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odf.sort_values('lnm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lnm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _lnm_(objd): return lnm_word(**objd)\n",
    "\n",
    "def lnm(\n",
    "        word_or_words,\n",
    "        period_or_periods=None,\n",
    "        run_or_runs=None,\n",
    "        cache=True,\n",
    "        force=False,\n",
    "        cache_only=False,\n",
    "        progress=True,\n",
    "        progress_nbr=False,\n",
    "        progress_word=None,\n",
    "        num_proc=1,\n",
    "        num_runs=NUM_RUNS_LNM,\n",
    "        k=K,\n",
    "        ymin=YMIN_NBR,\n",
    "        ymax=YMAX_NBR,\n",
    "        ybin=YBIN_NBR,\n",
    "        ):\n",
    "    words=tokenize_fast(word_or_words) if type(word_or_words)==str else list(word_or_words)\n",
    "    \n",
    "    objs=[\n",
    "        dict(\n",
    "            word=word,\n",
    "            period_or_periods=period_or_periods,\n",
    "            run_or_runs=run_or_runs,\n",
    "            word2=None,\n",
    "            cache=cache,\n",
    "            force=force,\n",
    "            k=k,\n",
    "            cache_only=cache_only,\n",
    "            progress=progress_word if progress_word is not None else (False if len(words)>1 else progress),\n",
    "            progress_nbr=progress_nbr,\n",
    "            num_proc=1 if len(words)>1 else num_proc,\n",
    "            ymin=ymin,ymax=ymax,ybin=ybin,\n",
    "            num_runs=num_runs\n",
    "        ) for word in words\n",
    "    ]\n",
    "    o=pmap(\n",
    "        _lnm_,\n",
    "        objs,\n",
    "        num_proc=num_proc if len(words)>1 else 1,\n",
    "        progress=progress if len(words)>1 else False,\n",
    "        desc='Measuring LNM across words',\n",
    "    )\n",
    "    return pd.concat(o) if len(o) else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lnm('virtue,vice,virtues,vices,values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lnm_precache_words(words=None,**y):\n",
    "    words_done=set()\n",
    "    with get_veclib('lnm') as vl:\n",
    "        words_done=set(k.split(',')[0] for k in vl.keys())\n",
    "    if not words: words=get_valid_words()\n",
    "    words=[w for w in words if not w in words_done]\n",
    "    lnm(words, cache_only=True,**y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words=get_valid_words()\n",
    "# random.shuffle(words)\n",
    "# res=pmap(do_word, words, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lnm_precache_words(get_all_nouns_adjs(), num_proc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons of magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=get_words_with_lnm()\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_lnm_word(word,valkey='lnm',min_n=20):\n",
    "    df=lnm_word(word)\n",
    "    if not len(df): return pd.DataFrame()\n",
    "    df=df.loc[word,word].reset_index()\n",
    "    df.period1=df.period1.apply(lambda ystr: periodize_sattelzeit(int(ystr[:4]), use_dates=False))\n",
    "    df.period2=df.period2.apply(lambda ystr: periodize_sattelzeit(int(ystr[:4]), use_dates=False))\n",
    "    df['period_cmp']=[f'{x}-v-{y}' for x,y in zip(df.period1,df.period2)]\n",
    "#     period_cmps={f'{x}-v-{y}' for x,y in zip(df.period1,df.period2) if x!=y}\n",
    "    period_cmps={f'{x}-v-{y}' for x,y in zip(df.period1,df.period2) if x==y}\n",
    "#     period_cmps={f'{x}-v-{y}' for x,y in zip(df.period1,df.period2)}\n",
    "    o=[]\n",
    "    for period_cmp in period_cmps:\n",
    "        g=df[df.period_cmp==period_cmp]\n",
    "        p1,p2=period_cmp.split('-v-')\n",
    "#         gnull=df[df.period_cmp.isin({f'{p1}-v-{p1}', f'{p2}-v-{p2}'})]\n",
    "        gnull=df[(df.period_cmp!=period_cmp) & df.period_cmp.isin(period_cmps)]\n",
    "        a=gnull[valkey]\n",
    "        b=g[valkey]\n",
    "        if len(a)<min_n or len(b)<min_n: continue\n",
    "        mw,mw_p=mannwhitneyu(a,b)\n",
    "        o+=[dict(\n",
    "            word=word,\n",
    "            vector='LNM',\n",
    "            period_cmp=period_cmp,\n",
    "            n1=len(a),\n",
    "            n2=len(b),\n",
    "            mw=mw,\n",
    "            mw_p=mw_p,\n",
    "            avg1=a.mean(),\n",
    "            avg2=b.mean(),\n",
    "        )]\n",
    "    df=pd.DataFrame(o)\n",
    "#     if len(df):\n",
    "#         df['avg_diff']=df.avg2 - df.avg1\n",
    "#         df['avg_div']=df.avg2/df.avg1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_lnm_word('sympathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_lnm_words(force=False,num_proc=1):\n",
    "    if not force and os.path.exists(FN_LNM_TTEST): return read_df(FN_LNM_TTEST)\n",
    "    \n",
    "    words=get_words_with_lnm()\n",
    "    o=pmap(\n",
    "        ttest_lnm_word,\n",
    "        words,\n",
    "        num_proc=num_proc\n",
    "    )\n",
    "    if not len(o): return pd.DataFrame()\n",
    "    odf=pd.concat(o) if len(o) else pd.DataFrame()\n",
    "    odf['mw_perc']=odf.mw.rank(ascending=False) / len(odf) * 100\n",
    "    odf=odf.set_index(['word','vector','period_cmp']).sort_values('mw')\n",
    "    odf=pd.concat(\n",
    "        vdf.assign(mw_perc_vec=vdf.mw.rank(ascending=False) / len(vdf) * 100)\n",
    "        for i,vdf in odf.groupby('vector')\n",
    "    )\n",
    "    odf=pd.concat(\n",
    "        vdf.assign(mw_perc_vec_cmp=vdf.mw.rank(ascending=False) / len(vdf) * 100)\n",
    "        for i,vdf in odf.groupby(['vector','period_cmp'])\n",
    "    )\n",
    "    odf=pd.concat(\n",
    "        vdf.assign(\n",
    "            avg1_perc_vec=(vdf.avg1.rank(ascending=False) / len(vdf) * 100),\n",
    "            avg2_perc_vec=(vdf.avg2.rank(ascending=False) / len(vdf) * 100),\n",
    "        )\n",
    "        for i,vdf in odf.groupby('vector')\n",
    "    )\n",
    "    \n",
    "    odf=odf.sort_index()\n",
    "    s=odf.avg1.append(odf.avg2)\n",
    "    odf.avg1 = (odf.avg1 - s.mean())/s.std()\n",
    "    odf.avg2 = (odf.avg2 - s.mean())/s.std()\n",
    "    odf['avg_diff']=odf.avg2 - odf.avg1\n",
    "    odf['avg_div']=odf.avg2/odf.avg1\n",
    "    \n",
    "    odf.to_pickle(FN_LNM_TTEST)\n",
    "    \n",
    "    # add to db\n",
    "    with get_veclib('ttest_lnm') as vl:\n",
    "        for w,wdf in tqdm(odf.groupby('word'),desc='Adding to db'):\n",
    "            vl[w]=wdf\n",
    "        print('Committing')\n",
    "        vl.commit()\n",
    "        print('Done')\n",
    "    \n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf=ttest_lnm_words(num_proc=4,force=True)\n",
    "odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf.query('period_cmp==\"Before-v-After\"').groupby('word').mean().sort_values('mw',ascending=True).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
